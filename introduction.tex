\section{Introduction} \label{sec:intro}
In a zero-knowledge proof protocol, a verifier tries to verify that an instance $x$ is in a language $L$. A prover with a witness $w$ to $x \in L$ tries to convince the verifier on this without revealing any additional information to the verifier than what he already knows. Be it proving that a user is single-spending a coin that he has earned before in a private manner \cite{zerocash} or validating sensitive web browser data reported during telemetry \cite{MozillaPrio}, ZK protocols have garnered immense interest over the last few years. Still in the dream of a decentralized world, there are multiple co-opetitive entities interacting with each other to obtain insights and maximize their goals. A desirable goal is to enable these mutually distrusting entities to prove a predicate on their joint data. But, the traditional \textit{single-prover} ZK setting is restrictive here since there is a single prover holding the entire witness required to prove the predicate. 

%\pdnote{do we want to motivate it in a way such that the honest prover setting we are looking at will suffice for the listed applications? }
In this work, we study the general setting of \textit{distributed prover zero-knowledge protocols} ($\DPZK$) where multiple co-opetitive i.e., collaborating but mutually distrusting entities each possessing their own secret data want to prove to a verifier that their secret data together satisfies a predicate of common interest. This is done without revealing any information about their sensitive data to each other or to the verifier, more than what each of them know about it beforehand. Some real-world applications follow:
\begin{itemize}
\item A simple but pertinent scenario is of a \textit{joint loan application} by an association of companies from a particular industry. The loan issuer has a set of financial requirements that it wants the association to satisfy, but there is no single trusted entity to act as the prover whom all the companies are willing to provide their sensitive business information with.
\item In cryptocurrency settings \cite{bitcoin, ethereum, zerocash}, this would enable a \textit{multi-wallet transaction} or a \textit{proof of joint stake}, which in turn enables secure collaboration applications by design on a blockchain network. % use it for joint auction-
\item In trade logistics business networks \cite{scbn, e2open, tradelens}, a major reason for businesses to enter these networks is to benefit from cross-industry statistics. Publishing these statistics in a publicly verifiable manner without having a single trusted entity is another embodiment of this setting.
\end{itemize}

In abstract terms, we have multiple provers $P_1, \ldots, P_{\Num}$ respectively possessing witnesses $\wit_1, \ldots, \wit_{\Num}$. For a predicate $C$ from the supported class of predicates $\cC$, the provers want to prove to a verifier that $C(w_1,\cdots,w_{\Num}) = 1$.
A natural solution for distributed proof generation is to start with the prover algorithm from a single prover protocol and run this algorithm between multiple provers using multi-party computation (MPC). Pedersen \cite{Ped92} proposed this notion and discussed this generic construction using MPC.
%Each round of proof generation is implemented by an MPC among the provers to generate the message to be sent to the verifier.
The generic construction is optimal in proof size and verifier complexity in that it retains these complexities from the single-prover version irrespective of the number of provers. But, the complexity of proof generation suffers when the single prover protocol is not constructed with distributed proof generation in mind. Even an optimal $R$-round proof generation algorithm with $O(N)$ multiplicative complexity of the prover's computation  might result in a distributed proof generation algorithm with $\Omega(R \cdot N)$ communication among the provers.
Prior works have improved the complexity of distributed proof generation $o(R \cdot N)$, but only when considering simple predicates involved in threshold signatures \cite{DDS}, range proofs \cite{bulletproofs}, and some sigma protocols \cite{EfficientTZ}, or when working with a weaker adversarial model \cite{trinocchio} \commentA{be little specific about the last work. what is the weaker setting? we have not set the standard adversarial setting yet and so when you say weaker, the reader cannot deduce with respect to what}.

The goal of this work is to study zero-knowledge protocols supporting \textit{arbitrary} predicates where the proof generation algorithm is ``MPC-friendly'' \commentA{elaborate/spend a sentence on what you mean by MPC-frieldly}. %The proof generation algorithm is usually measured for efficiency in terms of number of group operations and number of rounds of interaction with the verifier.
Our work first identifies complexity measures that a ZK protocol should optimize for to admit efficient distributed proof generation. We then construct a ZK protocol which is the state-of-art in these parameters. The discussions will focus on {\em public-coin. honest-verifier} protocols with a transparent setup \commentA{ do you want to include no setup as well; as per your definition of transparent, is it same as no setup; what kind of setup is a collision-resistant hash function?}, which is essentially the setting for real-world applications: 1) protocols with such verifiers can be converted to succinct non-interactive  arguments (zk-SNARGs)  via the Fiat-Shamir transform \cite{FS86, BCS16}, and  2) generating the parameters of the protocol should ideally {\em not} involve a trusted third party.
 %though a lot of it would also apply to protocols with a trusted setup. %producing a fixed or an updatable structured reference strings (SRS).

\subsection{Efficiency parameters for $\DPZK$}
In the single-prover setting, the efficiency of a proof generation algorithm is usually measured in terms of the number of arithmetic operations \commentA{you want to mention just multiplication; be specific} i.e., the \textit{proof generation computation complexity} ($\prcomm$) \commentA{but your parameter name $\prcomm$)  refers to communication complexity??}. The number of \textit{zero-knowledge rounds ($\zkrounds$)} of interaction between the prover and the verifier is also considered an efficiency parameter when a non-interactive prover is obtained from its interactive version in a provably secure manner \cite{BCS16}. \commentA{you haven't included proof size in this parameter list?} But, these parameters do not capture the core bottleneck in the setting of multiple provers.  \commentA{the following sentence looks misfit here and does not make any clear point. may be we should move it below after we explain the below parameters}
For instance, Spartan \cite{spartan} has an $O(N \log N)$ \commentA{unclear; you mean no. of multiplication or overall arithmetic operations? } proof generation algorithm, but due to the high multiplicative complexity of proof generation its straightforward distributed version requires $O(N^2)$ MPC multiplications where $N$ is the number of gates in the circuit representation of the predicate being proved.  \commentA{intuitively explain why the jump from $NlogN$ to $N^2$ happens}%Similar arguments will be made in a future section for the other state-of-art protocols like Aurora \cite{aurora}, Bulletproofs \cite{bulletproofs}. \dnote{mention the asymptotics in the above claims}

As a first step in our work, we identify parameters with significant impact in distributed proof generation. 
As indicated earlier, the first parameter of interest is \textit{proof generation communication}. This quantifies the amount of communication between the provers during the distributed proof generation. In general, this grows linearly with the circuit complexity of the proof generation algorithm for the practical MPC protocols. 
%\dnote{I am saying "practical" because there are RAM based protocols which do better than circuit complexity of the algorithm.}
But, there could also exist MPC protocols where the communication is only dependent on the number of cross-multiplications i.e., the multiplications between the witness bits from different parties. \commentA{section 1.2 should be here}
%, since an affine function over the witnesses and a multiplication between witness bits from the same prover can be computed without any interaction in a secret-sharing based MPC.

The next parameter of interest is the number of \textit{proof generation rounds ($\prrounds$)} which indicates the number of rounds of communication between the provers during the distributed proof generation. In a typical MPC, this parameter would be a constant number for the garbled-circuit based protocols and be the cross-multiplicative depth of the circuit for the secret-sharing based protocols. But in our setting, it is also relevant whether or not the MPC protocol transcends across the multiple $\zkrounds$. For each round of the interaction between the provers and the verifier, the provers have to compute their message for that round, in clear, to be sent to the verifier. Thus, even a garbled-circuit MPC based approach for distributed proof generation might result in $\prrounds$ be linear the number of $\zkrounds$, and hence not a constant with respect to the size of the instance unless $\zkrounds$ is also a constant. \commentA{it's hard to digest the above; what's the point you are trying to make; some of the zkRounds do not need MPC and hence we can get read of the linear independence of prRounds from zkRounds?  }
\dnote{The above point makes sense only for the interactive version. Should we also argue for non-interactive proof generation?-that it requires us to do hash inside MPC if MPC is not done for each step.} 
\commentA{I didn't understand your comment. other can help?}
This parameter $\prrounds$ is also of cryptographic interest. If there is more than one round of prover message generation which requires MPC, care has to be taken to ensure a secure composition of the individual MPCs to prove the complete protocol secure.

\subsection{Circuit share complexity}
Consider a predicate where the witness is \textit{partitioned} among the provers in the $\DPZK$ setting. We define a additional notion of efficiency for distributed proof generation which would be prominent for a class of real-world applications.
Let \textit{shared circuit} denote the part of the circuit representing the predicate whose wire values are functions of inputs from more than one prover. 
We introduce the notion of \textit{circuit share complexity} to denote the size of this shared circuit.
Consider the class of applications where hashes (or any other commitment) of data from different parties are stored on a blockchain and a zero-knowledge proof has to be generated on an aggregation of all the data. This could be: 
\begin{enumerate}
\item Finance network: different bank account holders proving to a loan provider that the sum of their account balances is greater than the required threshold.
\item Trade logistic network: different logistic providers proving to a customer or regulator that the average delay of shipment along a particular route is less than a specified time.
\end{enumerate}
In all the applications in this class, each party participating in the aggregation first proves the \textit{relevance} of his/her data before a humongous number of parties together run a protocol to prove the aggregated value on their data. The proof of relevance involves proving that the data corresponds to a commitment in the blockchain network by proving the knowledge of the opening of a commitment in the blockchain. 
For instance, when using verifying a hash commitment within a proof system which works with circuit representation of the relation, the proofs of relevance i.e. the hash verifications of the individual data take up most of the gates in the circuit. But each such verification rely only on data from a single party. The aggregation does involve data from multiple parties but this step requires a relatively smaller number of gates. Hence, the circuit share complexity is very small for such applications, compared to the total size of the circuit. A DPZK protocol with its complexities proportional to the circuit share complexity instead of the total circuit complexity can attain major savings for such applications. %In general, the compatibility of the commitment with function representation of the proof system plays a part in the above discussion. We will discuss the relevant work on this compatibility in more detail in Section \ref{sec:relatedwork}.
Looking ahead, the complexity of the interaction between the provers in our DPZK protocol will be linear only in the circuit share complexity of the circuit predicate to be proven, and not in the total size of the circuit. 

\subsection{Subtlety in proving zero-knowledge}
Before we delve into our DPZK construction, we would also provide a couple of subtle notes regarding the zero-knowledge property of DPZK protocols. This would shed some light on the rationale for some of the artefacts of DPZK protocols. In an DPZK protocol, the verifier is allowed to collude with a subset of provers to learn the witnesses of the other provers. A strong definition of zero-knowledge should ensure that this collusion does not learn any additional information than what they know before the protocol. Here, one should also consider the number of other provers involved in the proof generation as an additional information. In our protocols, we will allow all the provers to know the total number of provers involved. This will lead to a relaxed definition where a verifier colluding with a prover will additionally learn the total number of provers. This still does not let a standalone verifier learn the total number of provers during its interaction with the provers.

This subtle note also impacts the size of the oracles for the protocols in the IOP framework \cite{aurora, ligero}. The oracle and the answers to the oracle queries should be independent of the total number of provers. Hence, for the IOP-based protocols, the efficiency parameters discussed above should be optimized not only for the prover message generation but also for the oracle generation and the query answering.\footnote{In principle, generating the oracle or answering a query would form a part of the prover message generation when IOP is viewed in the lens of an arbitrary interactive protocol.}
The IOP-based protocols in the literature \cite{aurora, ligero} market their non-use of public-key cryptography and thus a potential post-quantum security feature. To achieve zero-knowledge in the distributed prover setting while retaining these features, at a high level, they have to incur the additional overhead in $\prcomm$ due to using information-theoretic MPC to also construct the oracle and answer oracle queries. %, in addition to using it for generating the prover messages.

Another subtle point here is that a single-prover ZK protocol provides the zero-knowledge property only for honest provers. The witness is not guaranteed to be hidden from the verifier if a prover deviates from the protocol. Hence, in a distributed prover setting it is non-trivial to prove or even define the zero-knowledge property if some of the provers deviate from the protocol or if they do not have the valid witness. We take these into account while defining the security notions of $\DPZK$ and when constructing our $\DPZK$ protocol.

\subsection{\name{}: an MPC-friendly zero-knowledge protocol}
We propose an MPC-friendly single-prover protocol \name{} with a transparent setup with $\prcomm$ linear in circuit size and a constant number of $\prrounds$.  
%This linear $\prComm$ is due to linear number of cross-multiplications which can be done concurrently, and hence the MPC is only performed on an $N$ mult-gates circuit of depth 1. 
\name{} achieves these properties while achieving proof size and verification complexity competitive with the state-of-art zero-knowledge protocols which do not admit efficient distributed proof generation. In particular, \name{} admits a proof size of $O(N^{1/c})$ for arbitrary $c\geq 2$, and a verification complexity of $O(N^{1-2/c})$ public key operations and $O(N)$ field operations. \name{} is a public-coin honest verifier zero-knowledge protocol that achieves the property of zero-knowledge-with-collusion i.e., the witnesses from a set of provers are not revealed to a verifier even when it colludes with the complimentary set of provers who are honest-but-curious.

%Efficiency Desiderata:  
%- Transparent setup 
%- Minimum interaction between the provers (\# of rounds of MPC) 
%- Total communication complexity of the msgs exchanged
%- verifiers view is indistinguishable from a single prover setting
%- How efficient is underlying zkp protocol (public key operations, size of proof, prover/ verification time)
%- Applicability to a general class of computation

%\paragraph{Technical overview}
%Our goal is construct a zero-knowledge protocol which optimizes all the efficiency parameters: $\zkcomm$ a.k.a., the proof size, $\zkrounds$, provers' complexity (represented by $\prcomm$ and $\prrounds$) and the verifier's complexity. We will now brief the MPC (non-)friendliness of the state-of-art protocols in the setting before we brief \name{}.
%
We provide a brief summary of ``direct'' transformations of the state-of-art zero-knowledge protocols in our setting into their $\DPZK$ versions.
The Interactive PCP (IPCP) protocol Ligero \cite{ligero} requires no public key operations during proof generation and hence admits efficient proof generation, in practice \cite{diogenes}, for a single prover. \dnote{Cite "Diogenes: Lightweight Scalable RSA Modulus Generation with a Dishonest Majority" which Carmit talked about in the workshop.}
But, Ligero and another oracle based construction Aurora \cite{aurora} do not directly admit distributed proof generation unless a generic MPC is applied for constructing their oracle and answering its queries. The Bulletproofs protocol \cite{bulletproofs} has one of the best proof sizes, but its prover algorithm involves $O(N)$ which makes it MPC unfriendly. %Also, its verifier requires $O(N)$ public key operations to verify a proof. 
Spartan \cite{spartan} admits sublinear verifier complexity in an amortized sense, but its prover again incurs $O(N^2)$ multiplications.

\name{} is an IPCP protocol that follows the outline of Ligero: (i) encoding the witness via a suitable error correcting code, (ii) checking linear relations on the witness, (iii) checking quadratic relations on the witness, and (iv) a proximity protocol to check that the witness is correctly encoded. The witness encoding is committed as an ``oracle'' and is queried during the linear, quadratic and the proximity checks. 
\paragraph{New encoding} A core technical contribution of our work is a novel way to encode the witness and thereby design the three checks in the zero-knowledge protocol around the new encoding. The \textit{witness} is represented as a \textit{3D matrix} of dimensions $p \times m \times n$ whose product is $O(N)$. The \textit{witness encoding} is obtained by encoding every $m \times n$ `slice' of the 3D matrix using a 2D product Reed-Solomon code. The \textit{oracle} is now obtained by committing each $O(m)$-sized `column' in the encoded witness using homomorphic vector commitments \cite{Ped??}. \dnote{what is the citation for Pederesen commitments?}
Our oracle is a $O(p \cdot n)$-sized matrix of commitments. The use of homomorphic vector commitments helps in two aspects: (i) enabling distributed proof generation and (ii) achieving proof sizes independent of the largest dimension of the matrix.
As we will see later, we will be able to regulate the three dimensions such that we get \textit{sub-linear} complexities in both the communication between the provers $\prcomm$ and the proof size $\zkcomm$. 
\paragraph{Proximity check} The proximity protocol checks that the encoding is well-formed by verifying that a random linear combination of the slices of the 3D matrix is \textit{near} to a 2D product code. This is sufficient due to the claim, that we prove, that a random linear combination of the rows is far from the codespace if at least one row of the matrix is far from the codespace. A Ligero-style proximity check protocol is additionally performed to check that the encoding used in the above step is the same one that is committed in the oracle. The salient feature of the above two steps is that the proof size $\zkcomm$ is independent of the largest dimension of the witness matrix and linear in the sum of the other two dimensions. We also carefully design the distributed proof generation protocol such that the communication between the provers $\prcomm$ is only linear in the largest dimension.
\paragraph{Linear check} The protocol to check the linear relations on the witness starts as in Ligero to reduce the checks to polynomial identity testing. We then design new steps to further reduce this test to multiple inner-product arguments on vectors of lengths linear in the individual dimensions of the 3D witness matrix. An additional check is performed to test the consistency of the inputs used in the inner-products with those committed in the oracle.
\paragraph{Quadratic check} This protocol follows the same set of steps as the linear check, except that additional MPC is required to obtain the inputs for the inner product arguments during distributed proof generation. The MPC will be required for $N$ independent multiplications between the witness bits and this would incur an additional $O(N)$ communication among the provers.\dnote{Check complexity in prev sentence.} To be more precise, the number of MPC multiplications and hence the communication would be linear in the circuit share complexity $O(N_s)$.

%\subsection*{Distributed proof generation}
%--- Informal notion of Distributed Provers Zero Knowledge Protocol $\innp{\Pi}{\verifier}$--- 
%
%A na\"ive approach to build a $\DPZK$ protocol is to take a single-prover ZK protocol and execute a multi-party computation among the provers of each message to be generated by the prover in the single-prover protocol. This satisfies the required security properties, but suffers in concrete efficiency when MPC is used over the proof generation as a black box. 
%
%\subsubsection*{Need for homomorphic commitments} 
%(Oracle access for IOP).
%The (non-interactive) zero-knowledge proof generation protocols based on the Interactive oracle proofs (IOP) or the Interactive PCP (IPCP) paradigms make use of \textit{oracles}. The prover establishes an oracle based on her witness. Once established, the IOP/IPCP protocols ensure that a prover will not modify the oracle further in the protocol. The verifier queries the oracle later in the protocol to verify some the claims made by the prover. When IOP/IPCP based proof systems are converted into the non-interactive setting, the establishment of the oracle is done by producing a commitment to the oracle entries.
%
%We will now run through a mental experiment on achieving distributed proof generation following the blueprint of the single-prover proof generation algorithm. We desire to not have the proof length depend on the number of parties. As we would discuss in depth later, we would also avoid running an MPC protocol on the proof generation circuit(s) of some zero-knowledge protocol. This would trivially, in theory, satisfy our goals, but it would be very inefficient in practice. The way we satisfy these goals for the establishment of the oracle is by requiring the oracle entries and their commitments satisfy homomorphic properties.
%\dnote{self: Sounds somewhat weak. Make it more compelling.}
%
%\subsection*{Technical summary}
%We will now provide a high-level summary of our work and along the way mention our core ideas.
%
%%Our contributions are two-fold: first in defining and constructing a zero-knowledge protocol with distributed proof generation and the second in proposing the first protocol with (expected) sub-linear verifier complexity.
%
%Our main contribution is defining and constructinf a zero-knowledge protocol with distributed proof generation.
%
%\paragraph{DPZK}
%We design a framework for constructing DPZK protocols starting from a single-prover ZK protocol.
%%To construct our DPZK protocol \name{} we follow the strategy of designing a (public coin honest verifier) single-prover ZK protocol whose proofs are ``aggregatable'' at minimal cost. 
%Let the parties $\prover_1, \ldots, \prover_{\Num}$ hold their respective witnesses $\wit_1, \ldots, \wit_{\Num}$ to the relation $R(\stmt, (\wit_1, \ldots,\wit_{\Num}))$. 
%Starting with a (public coin honest verifier) single-prover ZK protocol, there are two steps involved in our proof generation.
%\begin{itemize}
%\item The first step involves performing a secret sharing based MPC protocol on $R$ between the provers. As a result, each prover obtains her share of the extended witness, which includes all the wires (correspondingly variables) of a circuit (correspondingly R1CS) representation of R. 
%\item Next, for each message from the prover to the verifier, the parties perform the following two steps:
%\begin{itemize}
%\item The parties run an MPC protocol to obtain their share of the message. This step has a major implication on the efficiency of distributed proof generation. Depending on the single-prover protocol, some messages already posses homomorphism properties. Hence, the output of a local run of the single-prover algorithm for this round on a prover's shares of extended witness is already her share of the message in the distributed proof generation. When the message is not homomorphic, we design custom efficient protocols to obtain the shares of the message.
%\item One of the prover parties or an external entity trusted with the correctness of execution is chosen as an ``aggregator''. Aggregator is not trusted with the privacy of the inputs. The aggregator receives the shares of the messages from all the parties and performs the steps of the single-prover protocol to be performed with the aggregated message. Also, a prover acting as an aggregator does not have an incentive to deviate from executing the correct protocol during this step. This is because she could have caused the protocol to abort in any of the previous steps, and there is no additional information that she gains in the intermediate steps that aids her deviation in the aggregation step.
%\end{itemize}
%\end{itemize}
%
%Starting with the single-prover protocol of \cite{ours}, we design custom protocols so that the only additional interaction between the parties during the second step involves MPC for $\intpartofC$ concurrent multiplications, where $\intpartofC$ is the number of wires in the \textit{interactive} part of the circuit. Consider the check $x+y \stackrel{?}{=} z$ when given their respective hashes. If the inputs are present with three different parties, the corresponding circuit for the hash check followed by the addition and equality check involves extensive local computations for the hash before the interaction happens. \dnote{self: Provide a compelling real world use-case here} The additional communication complexity of our $\DPZK$ protocol grows only with the size of the interactive part. To enable this, we do.... start with \cite{ours} --- arrange the rows accordingly in the witness matrix --- 
%
%proof size independent of number of parties --- Oracle queries outputs should be independent of the number of parties --- we do it having parties generate a homomorphic oracle starting with their shares on the extended witness --- we would achieve indistinguishability between proof generated in a distributed manner and the proof generated by a single party ---
%In this, we use homomorphic commitments --- we follow from \cite{ours} --- 


\input{Related_work.tex}

%Let $P$ be the predicate that is being proved. An aggregation of multiple proofs on the same $P$ produces a proof.  Let us consider the interactive version of the protocol. A proof consists of the messages sent by the prover to the verifier and, additionally in IOPs, the replies to the oracle queries of the verifier.
%where each message from the prover is first identified whether it is homomorphic or not. If 
%each prover can produce an additive share of the proof.  find a way to \textit{aggregate} the proof parts from each prover. identify the prover messages which are homomorphic.
%
%the goals that we set for our construction
%
%the theme that we will have - require every message from prover to verifier be homomorphic.
%
%concrete starting point - ligero --- 
