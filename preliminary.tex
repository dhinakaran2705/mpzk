\section{Preliminaries}
\subsection{Linear Codes}
\begin{definition}\label{defn:lincode}
For positive integers $n,k$ and a finite field $\bbF$, a $k$-dimensional subspace $L$ of $\bbF^n$ is called an $[n,k]$ linear code. Elements of $L$ are conventionally called {\em codewords}. 
\end{definition}

For codewords $x,y\in L$ where $x=(x_1,\ldots,x_n)$ and $y=(y_1,\ldots,y_n)$ we define the hamming distance $\dham(x,y)=|\{i\in [n]: x_i\neq y_i\}|$. It is easily checked that $\dham$ defines a metric on $L$. The minimum distance of the code $L$, denoted by $\delta(L)$ is defined as $\min\{\dham(x,y):x,y\in L, x\neq y\}$.

For an $[n,k]$ code $L$, a $n\times k$ matrix $\calG$ is called a {\em generator matrix} iff (i) $\calG x\in L$ for all $x \in \bbF^k$ and (ii) $\calG x\neq \calG y$ for $x\neq y$. Clearly, such a matrix $\calG$ has rank $k$. Similarly an $n\times (n-k)$ matrix $\calH$ such that $y^T \calH = 0$ for all $y\in L$ is called a {\em parity check} matrix for $L$. It is easily seen that the above two matrices exist for any $[n,k]$ linear code $L$. We will assume that description of the linear code $L$ includes a generator matrix $\calG$ and a parity check matrix $\calH$.

\begin{definition}[Interleaved Code]\label{defn:interleavedcode}
For an $[n,k]$-linear code $L$ and a positive integer $m$, we define a {\em row interleaved code} $\ric{L}{m}$ to be the set of $m\times n$ matrices $A$ such that each row of $A$ is a codeword in $L$. Similarly, we define a {\em column interleaved code} $\cic{L}{m}$ to be the set of $n\times m$ matrices $B$ such that each column of $B$ is a codeword in $L$.
\end{definition}

For a linear $[n,k]$-code $L$ over the field $\bbF$, we observe that $\ric{L}{m}$ forms an $[n,k]$-code over the field $\bbF^m$ by viewing each column of the codeword $A\in \ric{L}{m}$ as a symbol in the field $\bbF^m$. Similarly, $\cic{L}{m}$ forms an $[n,k]$ code over $\bbF^m$ by viewing each row of the codeword $B\in \cic{L}{m}$ as a symbol in $\bbF^m$. For $A,A'\in \ric{L}{m}$, we define the distance $\dham(A,A')=|\{i\in [n]: A[\cdot,i]\neq A'[\cdot,i]\}|$ where the notation $X[\cdot,i]$ denotes the $i^{th}$ column of the matrix $X$. Similarly for $B,B'\in \cic{L}{m}$ we define $\dham(B,B')=|\{i\in [n]: B[i,\cdot]\neq B'[i,\cdot]\}|$.
 
\begin{definition}[Product Code]\label{defn:productcode}
Let $L_i$ be an $[n_i,k_i]$-linear code for $i=1,2$. We define the product code $L_1\oplus L_2$ to be the code consisting of $n_2\times n_1$ matrices $A$ such that each row of $A$ is a codeword in $L_1$ and each column of $A$ is a codeword in $L_2$. 
\end{definition}

Note that by definition, the product code $L_1\oplus L_2$ is a row interleaved code of $L_1$ and a column interleaved code of $L_2$, i.e $L_1\oplus L_2 =
\ric{L_1}{n_2}\cap \cic{L_2}{n_1}$. For $A,A'\in L_1\oplus L_2$, we define $\dham_1(A,A')=|\{i\in [n_1]: A[\cdot,i]\neq A'[\cdot,i]\}|$ and $\dham_2(A,A')=|\{i\in
[n_2]: A[i,\cdot]\neq A'[i,\cdot]\}|$. The distance $\dham_1$ corresponds to distance function of the code $\ric{L}{n_2}$, where we view $A,A'$ as codewords in $\ric{L}{n_2}$. Similarly, the distance $\dham_2$ corresponds to the distance function of the code $\cic{L}{n_1}$.

\begin{definition}[Reed Solomon Code]\label{defn:rscode}
An $[n,k]$-Reed Solomon Code $L\subseteq \bbF^n$ consists of vectors $(p(\eta_1),\ldots,p(\eta_n))$ for polynomials $p\in \bbF[x]$ of degree less than $k$ where $\eta_1,\ldots,\eta_n$ are distinct points in $\bbF$. We will use $\rsc{\eta}{k}$ to denote the Reed Solomon code with $\bm{\eta}=(\eta_1,\ldots,\eta_n)$ and $deg(p)<k$.
\end{definition}
   
The following lemma will be useful to us later. Intuitively it states that for a code $L$, if a matrix is ``far'' from an interleaved code of $L$, then a random linear combination of its rows is also likely to be far from the code $L$. 

\begin{lemma}\label{lem:proximitytest}
Let $L$ be an $[n,k]$ linear code and let $m$ be a positive integer. Let $U^*\in \bbF^{m\times n}$ be such that $\dham(U^\ast,\ric{L}{m})>e$ for $e<\delta(L)/3$. Then $\prob{\dham(r^TU^*,L)\leq e}<\delta(L)/|\bbF|$ where $r$ is sampled uniformly from $\bbF^m$.
\end{lemma}
The above lemma is proved in \cite{Ligero2017} for $e=\delta(L)/4$. We provide a self-contained proof of the above for $e=\delta(L)/3$ in Appendix.


\subsection{Inner Product Arguments}
We define an interactive protocol that allows proving inner product relation over committed values. 
\begin{definition}\label{defn:commscheme}
 A pair of $\ppt$ algorithms $(\gen,\com)$ constitute a non-interactive commitment scheme if $\sigma\sample \gen(\secparam)$ consists of description of sets $\calM_\sigma$ (message space), $\calR_\sigma$ (randomness space), $\calC_\sigma$ (commitment space) and an efficiently computable function $\com_\sigma: \calM_\sigma\times \calR_\sigma\rightarrow \calC_\sigma$ which is {\em hiding} and {\em binding} as defined later.
\end{definition}

For $x\in \calM_p$, we generate a {\em commitment} of $x$ as $\com_\sigma(x,r)$ where $r\sample \calR_p$ is drawn uniformly at random. For ease of notaion, we simply use $\com$ instead of $\com_\sigma$ and use $\com(x)$ to denote the random variable corresponding to commitment of $x$. 

\begin{definition}[Hiding Commitment]\label{defn:hidingcomm}
A commitment scheme $(\gen,\com)$ is called {\em hiding} (perfectly) if for all $\ppt$ adversaries $\adv$, the following probability is negligibly close to $1/2$:
\begin{align*}
\condprob{b=b'}{
\begin{array}{l}
\sigma\sample \gen(\secparam); \\
(x_0,x_1)\in \calM^2_p\sample \adv(\sigma); \\
b\sample \bitset; c\sample \com(x_b);\\
b'\sample \adv(\sigma,c)
\end{array}
}
\end{align*}
\end{definition}

\begin{definition}[Binding Commitment]\label{defn:bindingcomm}
A commitment scheme $(\gen,\com)$ is called {\em binding} if for all $\ppt$ adversaries $\adv$, 
\begin{align*}
\condprob{\com_p(x_0,r_0)=\com_p(x_1,r_1)\wedge x_0\neq x_1}{
\begin{array}{l}
\sigma\sample \gen(\secparam) \\
x_0,x_1,r_0,r_1 \sample \adv(\sigma)
\end{array}
} < \negl
\end{align*}

\end{definition}

We will assume that all the message spaces $\calM_\sigma$ output by the $\gen$ algorithm come equipped with an inner product operator $\innp{.}{.}:\calM_\sigma\times \calM_\sigma\rightarrow Z$. We define the language $\calL_\sigma\subseteq \calC_\sigma\times \calC_\sigma\times Z$ as:
\begin{equation*}
\calL_\sigma = \{(c_1,c_2,v):\exists x_1,x_2,r_1,r_2 \text{ s.t. }
c_1=\com(x_1,r_1), c_2=\com(x_2,r_2) \text{ and } \innp{x_1}{x_2}=v\} 
\end{equation*}

The $\NP$ relation $\calR_\sigma$ for the language $\calL_\sigma$ consists of pairs $(\stmt,\wit)$ with $\stmt=(c_1,c_2,v)$ and $\wit=(x_1,x_2,r_1,r_2)$ such that $c_1=\com(x_1,r_1)$, $c_2=\com(x_2,r_2)$ and $\innp{x_1}{x_2}=v$ 

\begin{definition}[Inner Product Argument]\label{defn:innerproductarg}
We call an interactive protocol $(\pip,\vip)$ consisting of $\ppt$ interactive algorithms $\pip$ and $\vip$ an inner product argument for commitment scheme $(\gen,\com)$ if it recognizes the language $\calL_\sigma$ as defined previously. Namely, $\innp{\pip}{\vip}$ satisfies the following:
\begin{enumerate}[{\rm (i)}]
\item {\bf Completeness}: For all adversaries $\adv$,
\begin{align*}
\condprob{(\stmt,\wit)\in \calR_\sigma \vee \langle \pip(\sigma,\stmt,\wit),\vip(\sigma,\stmt)\rangle={\tt accept}}{
\begin{array}{l}
\sigma\sample \gen(\secparam);\\
(\stmt,\wit)\sample \adv(\sigma)
\end{array}
}=1
\end{align*}

\item{\bf Soundness}: For all deterministic polynomial time $\prover^*$ and$\ppt$ adversaries $\adv$:
\begin{align*}
\condprob{\stmt\not\in \calL_\sigma \wedge \langle
\prover^*(\sigma,\stmt,s),\vip(\sigma,u)\rangle={\tt accept}}{
\begin{array}{l}
\sigma\sample \gen(\secparam);\\
(\stmt,s)\sample \adv(\sigma)
\end{array}
} = \negl(\lambda)
\end{align*}
\end{enumerate}
\end{definition}

We mention some concrete instantiations of commitment schemes and corresponding inner product arguments that we use in our protocol.

\noindent{\em Logarithmic Inner Product Argument}: In this setting we have $\calM_\sigma=\bbZ^n_p$, $\calR_\sigma=\bbZ_p$, $\calC_\sigma=\bbG$ where $\bbG$ is group of prime order $p$. The algorithm $\gen$ samples generators $g_1,\ldots,g_n$, $h$ $\sample \bbG$. The commitment is a pederson vector commitment given by $\com({\bf x } ,r ) = h^r \cdot \prod_{i=1}^n {g_i}^{x_i}$ where ${\bf x}=(x_1,\ldots,x_n)$. We use the inner product argument $(\piplog,\viplog)$ from Bootle et.al in \cite{Bulletproofs} for the commitment scheme $(\gen,\com)$. The interactive protocol $(\piplog,\viplog)$ is a $O(\log n)$ round protocol with argument size $O(\log n)$. Time complexity of the verifier $\viplog$ is given by $t(\viplog)=O(n).\bbZ_p + O(n).\bbG$.\smallskip


\noindent{\em Square Root Inner Product Argument}: In this setting we use the same commitment scheme as above. For the inner product argument we use the interactive protocol $(\pipsq,\vipsq)$ from \cite{InnerProductDLS} or \cite{Groth09b}. The construction in \cite{InnerProductDLS} gives a $5$-move protocol with total communication complexity $O(\sqrt{n})$. The construction in \cite{Groth09b} gives a 7-move protocol with $O(\sqrt{n})$ communication complexity. In both the constructions $t(\vipsq) = O(n).\bbZ_p +
O(\sqrt{n}).\bbG$.



%--------------------------------Protik's prelims--------------------------------
%\subsection{Codes}
%\paragraph{\textbf{Reed-Solomon Code:}} For positive integers $n,k$, finite field $\mathbb{F}$, and a vector $\eta = (\eta_1,\cdots ,\eta_n) \in \mathbb{F}_n$ of distinct field elements, the code $RS_{\mathbb{F},n,k,\eta}$ is the $[n,k,n-k+1]$ linear code over $\mathbb{F}$ that consists of all $n$-tuples $(p(\eta_1),...,p(\eta_n))$ where $p(\cdot)$ is a polynomial of degree $< k$ over $\mathbb{F}$.
%\dnote{Comments for Protik:\\
%1. Have spaces between paragraphs even in Latex. The PDF generated by Latex is usually beautiful and readable. The tex file can't be beautiful but should atleast be as readable as the PDF.\\
%2. I have already told you many times, and I am not going to leave till you use it :) Use macro for any notation that you use more than two times throughout the paper. (You will realize the use of it the day we decide change some notation in the middle of writing a paper.. But it is also a good practice to do it in general).\\
%3.Use \ ldots for ...\\
%4. You could use subsection* or subsubsection* instead of having a paragraph and using a textbf inside. (try both, what looks better depends on the cls file you use).}
%\paragraph{\textbf{Interleaved Code:}} Let $L\subset \mathbb{F}_n$ be an $[n,k,d]$ linear code over $\mathbb{F}$. We let $L^m$ denote the $[n,mk,d]$ (interleaved) code over $\mathbb{F}^m$ whose code words are all $m\times n$ matrices $U$ such that every row $U_i$ of $U$ satisfies $U_i\in L$. For $U\in L^m$ and $j\in[n]$, we denote by $U[j]$ the $j^{th}$ symbol (column) of $U$.
%\dnote{Have "th" in jth outside math mode.}
%
%\subsection{Interactive Oracle Proofs} The Interactive Oracle Proofs is the notion which combine both Interactive Proofs and Probabilistically Checkable Proofs, and also generalize the notion of the Interactive PCPs.
%\paragraph{} A $k$-round public-coin IOP has $k$ rounds of interaction. In the $i^{th}$ round of interaction, the verifier sends a uniformly random message $m_i$ to the prover; then the prover replies with a message $\pi_i$ to the verifier. After $k$ rounds of interaction, the verifier makes some queries to the oracles it received and either accepts or rejects.
%\dnote{Have at least the main definitions in the Definition environment.}
%\paragraph{} An IOP system for a relation $\mathcal{R}$ with round complexity $k$ and soundness error $\epsilon$ is a pair $(P, V )$, where $P, V$ are probabilistic algorithms, that satisfies the following properties:
%\paragraph{\textit{Completeness:}}  For every instance-witness pair $(x,w)$ in the relation $\mathcal{R}, (P (x, w), V (x))$ is a $k(n)$-round interactive oracle protocol with accepting probability 1.
%\paragraph{\textit{Soundness:}} For every instance $x \notin \mathcal{L(R)}$ and unbounded malicious prover $P^*, (P^*, V (x))$ is a $k(n)$-round interactive oracle protocol with accepting probability at most $\epsilon(n)$.
%\subsection{Zero-Knowledge} 
%\paragraph{\textbf{Interactive Argument Systems:}} A pair of PPT(Probabilistic Polynomial Time) interactive machines $<P, V>$ is called an interactive proof system for a language $\mathcal{L}$ if there exists a negligible function $negl(\cdot)$ such that the following two conditions hold:
%\dnote{1. have space before a ( or any other bracket.\\
%2. Use \ langle and \ rangle instead of $<$ and $>$ when using it as brackets.
%3. You can have negl in mathsf, it would look better (have a macro for this too!)}
%\begin{itemize}
%	\item[(1)] \textit{Completeness:} For every $x\in \mathcal{L}$ there exists a string $w$ such that for every $z \in \{0,1\}^*$,
%$Pr[<P(x,w),V(x,z)>=1] \geq 1-negl(|x|)$.
%	\item[(2)] \textit{Soundness:} For every $x \notin \mathcal{L}$, every interactive PPT machine $P^*$, and every $w,z\in \{0,1\}^*$ $Pr[<P^*(x,w),V(x,z)>=1]\leq negl(|x|)$ 
%\end{itemize}
%\paragraph{\textbf{Zero Knowledge:}} Let$<P,V>$ be an interactive proof system for some language $\mathcal{L}$. We say that $<P,V>$ is computational zero-knowledge with respect to an auxiliary input if for every PPT interactive machine $V^*$ there exists a PPT algorithm $S$, running in time polynomial in the length of its first input, such that $\{<P(x,w),V^*(x,z)>\}_{x\in \mathcal{L},w\in \mathcal{R}_x,z\in \{0,1\}^*}\approx_c \{<S(x,z)>\}_{x\in\mathcal{L},z\in\{0,1\}^*}$
%\subsection{Commitment schemes} 
%\paragraph{\textbf{Commitemnts:}} A non-interactive commitment scheme consists of a pair of probabilistic polynomial time algorithms $(Setup,Com)$. The setup algorithm $pp\leftarrow Setup(1^{\lambda})$ generates public parameters $pp$ for the scheme, for security parameter $\lambda$. The commitment algorithm $Com_{pp}$ defines a function $M_{pp} \times R_{pp} \rightarrow C_{pp}$ for message space $M_{pp}$, randomness space $R_{pp}$ and commitment space $C_{pp}$ determined by $pp$. For a message $x\in M_{pp}$, the algorithm draws $\delta \in_R  R_{pp}$ uniformly at random, and computes commitment $\com = Com_{pp}(x; \delta)$.\\
%For ease of notation we write $Com = Com_{pp}$.
%\dnote{All algorithm names in mathsf (macro for each). Eg. in the above paragraph, Setup, Com, ...}
%\paragraph{\textbf{Homomorphic Commitment:}} A homomorphic commitment scheme is a non-interactive commitment scheme such that $M_{pp},R_{pp}$ and $C_{pp}$ are all abelian groups, and for all $x_1,x_2 \in M_{pp}, \delta_1,\delta_2 \in R_{pp}$, we have $Com(x_1; \delta_1) + Com(x_2; \delta_2) = Com(x_1 + x_2; \delta_1 + \delta_2)$
%\dnote{Hiding and binding are the core properties of a commitment scheme, i.e., a definition of a commitment scheme includes the properties of hiding and binding. So bring them first. And just mention ``Hiding'' and ``Binding''.}
%\paragraph{\textbf{Hiding Commitment:}} A commitment scheme is said to be hiding if for all PPT adversaries $\Adv$ there exists a negligible function $\mu(\lambda)$ such that
%$$ |Pr[b=b'|pp\leftarrow Setup(1^{\lambda}); (x_0,x_1)\in M^2_{pp}\leftarrow \Adv(pp), b\in_R\{0,1\}, \delta \in_R R_{pp}, \com=Com(x_b;\delta), b'\leftarrow \Adv(pp,com)]-\frac{1}{2}|\leq \mu(\lambda)$$
%\paragraph{\textbf{Binding Commitment:}} A commitment scheme is said to be binding if for all PPT adversaries $\Adv$ there exists a negligible function $\mu$ such that 
%$$Pr[Com(x_0;\delta_0)=Com(x_1,\delta_1) \wedge x_0\neq x_1| pp\leftarrow Setup(1^{\lambda})x_0,x_1,\delta_0, \delta_1\leftarrow \Adv(pp)]\leq \mu(\lambda)$$
%\dnote{Have a subsection* with Pedersen commitment, and have the vector commitment also in the same part.}
%\paragraph{\textbf{Pedersen Commitment:}} $M_{pp}, R_{pp} = \mathbb{Z}_p, C_{pp} = \mathbb{G}$ of order $p$.\\
%$Setup : g, h \in_R \mathbb{G}$\\
%$Com(x,\delta)=(g^xh^{\delta})$
%\paragraph{\textbf{Pedersen Vector Commitment:}} $M_{pp}= \mathbb{Z}^n_p , R_{pp} = \mathbb{Z}_p, C_{pp}= \mathbb{G}$ with G of order p.\\ 
%$Setup: \vc{g}=(g_1,\cdots,g_n),h \in_R \mathbb{G}$\\
%$Com(\vc{x} = (x_1,\cdots,x_n);\delta) = h^r\vc{g}^{\vc{x}} = h^r \prod\limits_i g_i^{x_i} \in \mathbb{G}$