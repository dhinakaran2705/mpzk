\section{Notations and Preliminaries}\label{sec:prelims}
\subsection{Basic Notations}\label{sec:basicnotation}
In this section, we describe the notation that will be followed in rest of the
paper. We will often recall the notation in appropriate places. 
We use $[n]$ to
denote the set $\{1,\ldots,n\}$. All the arithmetic circuits and constraint
systems are assumed to be defined over finite field denoted by $\FF$. For a
vector $x\in \FF^m$, we implicitly assume $x_i$ represents the $i^{th}$
component of $x$ for $i\in [m]$. Whenever suitable, we will also use $x[i]$ to
denote $i^{th}$ entry of a vector $x$. We naturally extend the notation $[\cdot]$ to
index matrices and three dimensional matrices. For an $m\times n$ matrix over
$\FF$, we use $A[i,j]$ to denote $(i,j)^{th}$ entry of $A$. We use $A[i,\cdot]$
to denote the $i^{th}$ row of $A$ and $A[\cdot,j]$ to denote $j^{th}$ column of
$A$. Similarly, for an $p\times m\times n$  matrix $X$, we use $X[i,j,k]$ to
denote the $(i,j,k)^{th}$ entry of $X$. The notation $X[i,\cdot,\cdot]$ denotes
the $m\times n$ matrix $Y$ given by $Y[j,k] := X[i,j,k]$. 
Analogously,
$X[\cdot,j,\cdot]$ and $X[\cdot,\cdot,k]$ denote $n\times p$ and $p\times m$
matrices respectively. For three dimensional
matrix $X$, we will refer to sub-matrices $X[i,\cdot,\cdot]$ as {\em slices} of
$X$, sub-matrices $X[\cdot,j,\cdot]$ as {\em slabs}  of $X$ and sub-matrices $X[\cdot,\cdot,k]$ as the {\em planes} of $X$. 
$X^T$ denotes transpose of a  two dimensional matrix $X$. Inner-product of two vectors $X,Y$ is denoted as $\langle X,Y\rangle$.
Inner-product of two three or two dimensional  matrices $X$ and $Y$, denoted as 
$\langle X,Y\rangle$,  implies the inner-product of the corresponding one-dimensional vectors obtained from unrolling  the matrices.


Throughout the paper we use several distance metrics on vectors and matrices,
which we now introduce. For two vectors $x,y$ of length $n$, we define
$\Delta(x,y)=|\{i\in [n]: x_i\neq y_i\}|$. For two $m\times n$ matrices $A,B$ we
define $\Delta_1(A,B)=|\{j\in [n]: A[\cdot,j]\neq B[\cdot,j]\}|$ and
$\Delta_2(A,B)=|\{i\in [m]: A[i,\cdot]\neq B[i,\cdot]\}|$. For $p\times m\times
n$ matrices $X$ and $Y$, we define $\Delta_1(X,Y)=\{k\in
[n]:X[\cdot,\cdot,k]\neq Y[\cdot,\cdot,k]\}$ (no of planes that are different between the two matrices). Similarly we define $\Delta_2(X,Y)
= |\{j\in [m]: X[\cdot,j,\cdot]\neq Y[\cdot,j,\cdot]\}|$  (no of slabs that are different between the two matrices). Let $u$ be a vector
and $S$ be a set of vectors. We use $d(u,S) := \min\{\Delta(u,v):v\in S\}$ to
denote distance between $u$ and $S$. Similarly for a matrix (two or three
dimenional) $U$ and a set of matrices $\mc{M}$, we define $d_i(U,\mc{M}) :=
\min\{\Delta_i(U,M): M\in \mc{M}\}$ for $i=1,2$.





We use $\sample$ to denote drawing from a distribution uniformly at random.


\begin{comment} 
\subsection{Notations for Protocols}
We describe some of the notation that we use to describe our protocols. We
notate our interactive protocols with a name and a list of parameters. The
parameters to the left of semicolon ($;$) are assumed to be {\em public}, while those to the
right of the semicolon are considered {\em private} inputs of the prover. For example
$\innerproduct(\FF,\GG,\bm{g},x,\mathsf{cm},v;z)$ denotes a protocol with $6$
public parameters and a private parameter $z$. We enclose a public parameter in
brackets ($[\,]$) to denote ``oracle'' access to the parameter (i.e, it can only
be partially queried by the verifier). As an illustration
$\proximityThreeD(\FF,\GG,L_1,L_2,[\pi];\ewit)$ denotes a protocol, where the
verifier only has oracle access to $\pi$. Finally, in the distributed setting,
some of the private inputs may be additively secret shared  across multiple provers. We notate it
by enclosing those private inputs in $\langle\,\rangle$. For example, in the protocol
$\proximityTwoD(\FF,\GG,\ell,L_1,L_2,\bm{c};\langle \bar{U} \rangle)$, each prover
$\distprover$ only has a share $\shr{\bar{U}}$ of the matrix $\bar{U}$.
\pnote{Changes required}
\end{comment}

\subsection{Linear Codes}
\begin{definition}\label{defn:lincode}
Let $n,k,d$ be positive integers with $n\geq k$ and $\FF$ be a finite field. We
call $L\subseteq \FF^n$ to be an $[n,k,d]$ linear code if $L$ is a $k$-dimensional
subspace of $\FF^n$ and $d$ is the minimum value of $\Delta(x,y)$ for distinct
$x,y\in L$. Elements of $L$ are conventionally called {\em codewords}.
\end{definition}

For an $[n,k,d]$ code $L$, an $n\times k$ matrix $\calG$ is called a {\em
generator matrix} for $L$ iff (i) $\calG x\in L$ for all $x \in \bbF^k$ and (ii)
$\calG x\neq \calG y$ for $x\neq y$. Clearly, such a matrix $\calG$ has rank
$k$. Similarly an $n\times (n-k)$ matrix $\calH$ such that $y^T \calH = 0$ for
all $y\in L$ is called a {\em parity check} matrix for $L$. It is known
that the above two matrices exist for any $[n,k,d]$ linear code $L$. We will
assume that description of the linear code $L$ includes a generator matrix
$\calG$ and a parity check matrix $\calH$.

\begin{definition}[Interleaved Code]\label{defn:interleavedcode}
For an $[n,k,d]$ linear code $L$ and a positive integer $m$, we define a {\em row interleaved code} $\ric{L}{m}$ to be the set of $m\times n$ matrices $A$ such that each row of $A$ is a codeword in $L$. Similarly, we define a {\em column interleaved code} $\cic{L}{m}$ to be the set of $n\times m$ matrices $B$ such that each column of $B$ is a codeword in $L$.
\end{definition}

%Let $L$ be a linear $[n,k,d]$ code over the field $\FF$ and let $\mc{C}=\ric{L}{m}$ be the row interleaved code of $L$. 
For  an  $[n,k,d]$ linear code $L$ over $\FF$, one can view $\ric{L}{m}$ as
an $[mn,mk,d]$ linear code over  $\FF$ or alternatively,  as an $[n,k,d]$ code over $\HH$, where $\HH\cong \FF^m$. %We elaborate on this correspondence in Appendix \ref{app:AltILC}.

Analogous to the row interleaved code, a column interleaved code $\cic{L}{m}$ 
can be viewed as an $[n,k,d]$ code over $\bbF^m$ by viewing each row of the
codeword $B\in \cic{L}{m}$ as an element in $\bbF^m$. Here the distance metric
for $\ric{L}{m}$ is given by the matrix distance $\Delta_1$, while the distance
metric for $\cic{L}{m}$ is given by the matrix distance $\Delta_2$ as defined in
Section \ref{sec:basicnotation}.  
 
\begin{definition}[Product Code]\label{defn:productcode}
Let $L_i$ be an $[n_i,k_i,d_i]$-linear code for $i=1,2$. We define the product
code $L_1\otimes L_2$ to be the code consisting of $n_2\times n_1$ matrices $A$
such that each row of $A$ is a codeword in $L_1$ and each column of $A$ is a
codeword in $L_2$.
\end{definition}

Note that by definition, the product code $L_1\otimes L_2$ is a row interleaved
code of $L_1$ and a column interleaved code of $L_2$, i.e $L_1\otimes L_2 =
\ric{L_1}{n_2}\cap \cic{L_2}{n_1}$. For $A,A'\in L_1\otimes L_2$, we define
$\dham_1(A,A')=|\{i\in [n_1]: A[\cdot,i]\neq A'[\cdot,i]\}|$ and
$\dham_2(A,A')=|\{i\in [n_2]: A[i,\cdot]\neq A'[i,\cdot]\}|$. The distance
$\dham_1$ corresponds to distance function of the code $\ric{L}{n_2}$, where we
view $A,A'$ as codewords in $\ric{L}{n_2}$. Similarly, the distance $\dham_2$
corresponds to the distance function of the code $\cic{L}{n_1}$.

\begin{definition}[Reed-Solomon Code]\label{defn:rscode}
An $[n,k]$-Reed Solomon Code $L\subseteq \bbF^n$ consists of vectors
$(p(\eta_1),\ldots,p(\eta_n))$ for polynomials $p\in \bbF[x]$ of degree less
than $k$ where $\eta_1,\ldots,\eta_n$ are distinct points in $\bbF$. We will use
$\rsc{\eta}{n,k}$ to denote the Reed Solomon code with
$\bm{\eta}=(\eta_1,\ldots,\eta_n)$ and $deg(p)<k$. 
\end{definition}

\begin{lemma}[\cite{CodingTheory}]\label{lem:bicdecoding}
%Let $L_1 := \rsc{\eta}{n,\ell}$ and $L_2 := \rsc{\alpha}{h,m}$ be $[n,\ell]$ and $[h,m]$ Reed Solomon codes respectively. Let $\mc{C}_1 := \ric{L_1}{h}$ and $\mc{C}_2 := \cic{L_2}{n}$ be the interleaved codes of $L_1$ and $L_2$. 
Suppose
a matrix $U^\ast\in \FF^{h\times n}$ satisfies $d_1(U^\ast, \ric{\rsc{\eta}{n,\ell}}{h})<e_1 \leq n-\ell $ and
$d_2(U^\ast, \cic{ \rsc{\alpha}{h,m}}{n})<e_2 \leq h-m$.
Then, there exists $U\in \rsc{\eta}{n,\ell} \otimes \rsc{\alpha}{h,m}$ and sets
$S_1\subseteq [n]$, $S_2\subseteq [h]$ with $|S_1|>n-e_1$ and $|S_2|>h-e_2$ such
that $U^\ast[i,j]=U[i,j]$ for $(i,j)\in S_1\times S_2$.
\end{lemma}
%The proof is given in Appendix~\ref{prooflemmaRScode}.
%The proof is standard and  will be given in full version.
 

\subsection{Coding Theoretic Results for our Constructions}
In this section we prove the coding theoretic result (Proposition \ref{lem:3dcompression}), which underlies
the construction of our new ``MPC-friendly'' zero-knowledge protocol. The result
extends the approach in \cite{ligero}  of interleaving the witness and checking proximity (to well-formed encoding) by
compressing along a dimension using a random linear combination. 
While in \cite{ligero}, the witness was interleaved as a matrix,
we interleave the witness as a three-dimensional matrix to obtain smaller
argument size. The following result is the key to testing proximity of a three-dimensional matrix to a well-formed encoding. The proof  appears in Appendix \ref{app:ProofofLem3dcompression}.
\begin{proposition}[3D Compression]\label{lem:3dcompression}
Let $L$ be an $[n,k,d]$ code over $\FF$, and $\mc{C} :=
\ric{L}{m}$ be a row interleaved code of $L$. Let $\mc{C}^p$ denote the set of
$p\times m\times n$ matrices $U$ over $\FF$ such that $U[i,\cdot,\cdot]\in
\mc{C}$ for all $i\in [p]$. Let $U^\ast$ be a
$p\times m\times n$ matrix such that $d_1(U^\ast,\mc{C}^p)>e$.  Then for any
$m\times n$ matrix $u_0$ over $\FF$, we have 
\[ \prob{d_1\left(u_0 + \sum_{i=1}^p r_iU^\ast[i,\cdot,\cdot], \mc{C}\right)\leq e}\leq
\frac{d}{|\FF|}\]  
for a uniformly sampled $(r_1,\ldots,r_p)\sample \FF^p$. 
\end{proposition}


\subsection{Vector Commitment Schemes and Inner-product Arguments}
We define an interactive protocol that allows proving inner-product relation over committed vectors, where the commitment corresponds to a non-interactive perfectly hiding and computationally binding commitment scheme, with an additional property of homomorphicity.  We use Pedersen vector commitment scheme $\comm$ with message space $\FF^m$,
commitment space $\GG$ and randomness space $\FF$. For a set of generators
$\bm{g}=(g_1,\ldots,g_m,h)$, the commitment of vector $x\in \FF^m$ with commitment
randomness $r\in \FF$ is given by $\comm(x,r)=h^r \prod_{i=1}^m (g_i)^{x_i} $.
This commitment is homomorphic with $\calC=\GG$ as the commitment space.
%defined in Appendix \ref{app:DefCommitment}   
%We will assume that all the message spaces $\calM_\sigma$ output by the $\gen$ algorithm come equipped with an inner-product operator $\innp{\cdot}{\cdot}:\calM_\sigma\times \calM_\sigma\rightarrow Z$. 
We now define the language for inner-product w.r.t. the above  as $\calL
\subseteq \FF^m \times \calC \times \FF$ given by:
\begin{equation*}
%\begin{aligned}[c]
\begin{array}{l}
\calL = \{(x,c,z):\exists \; y,r \text{ s.t. } 
c=\com(y,r)  \text{ and } \innp{x}{y}=z\} 
%\end{aligned}
\end{array}
\end{equation*}

%The $\NP$ relation $\calR_\sigma$ for the language $\calL_\sigma$ consists of pairs $(\stmt,\wit)$ with $\stmt=(c_1,c_2,v)$ and $\wit=(x_1,x_2,r_1,r_2)$ such that $c_1=\com(x_1,r_1)$, $c_2=\com(x_2,r_2)$ and $\innp{x_1}{x_2}=v$.
 Interestingly, the inner-product argument is used to save on communication.
Proving  an inner-product statement requires sending $y$ on clear which costs
more than the argument-size. Our language for inner-product is a simpler version
of the one defined in ~\cite{bulletproofs}, where the first argument is also hidden in a commitment. 
\begin{definition}[Inner-product Argument \cite{InnerProductDLS,bulletproofs} ]\label{defn:innerproductarg} 
We call an interactive protocol $\innp{\pip}{\vip}$ consisting of $\ppt$ interactive algorithms $\pip$ and $\vip$ an inner-product argument for commitment scheme $(\gen,\com)$ if it recognizes the language $\calL$ as defined previously. Namely, $\innp{\pip}{\vip}$ satisfies the following:
\begin{enumerate}[{\rm (i)}]
\item {\bf Completeness}: For all adversaries $\adv$,
%\begin{align*}
%\condprob{(\stmt,\wit)\in \calR_\sigma \vee \langle \pip(\sigma,\stmt,\wit),\vip(\sigma,\stmt)\rangle=1}{
%\begin{array}{l}
%\sigma\gets \gen(\secparam);\\
%(\stmt,\wit)\gets \adv(\secparam,\sigma)
%\end{array}
%}=1
%\end{align*}
\footnotesize %\\~
\begin{align*}
\condprob{
	\begin{array}{l}
	(\stmt,\wit)\in \calR \wedge \\ \langle \pip(\sigma,\stmt,\wit),\vip(\sigma,\stmt)\rangle=1
	\end{array}}{
	\begin{array}{l}
	\sigma\gets \gen(\secparam);\\
	(\stmt,\wit)\gets \adv(\secparam,\sigma)
	\end{array}
}
=1
\end{align*}
\normalsize

\item{\bf Soundness}: For all deterministic polynomial time $\prover^*$ and $\ppt$ adversaries $\adv$:
\footnotesize %\\~
\begin{align*}
\condprob{
	\begin{array}{c}
	\stmt\not\in \calL \wedge \\
	\langle
\prover^*(\sigma,\stmt,s),\vip(\sigma,u)\rangle=1
\end{array}}{
\begin{array}{l}
\sigma\gets \gen(\secparam);\\
(\stmt,s)\gets \adv(\secparam,\sigma)
\end{array}
} = \negl(\lambda)
\end{align*}

\end{enumerate}

\end{definition}

%We mention some instantiations inner-product arguments in Appendix~\ref{inner-product-instan}.  
\commentA{something wrong here. bring back the bulletproof ref}
We are using inner product argument from Bulletproofs \cite{bulletproofs}.
we will be using a variant of inner product where one of the vector is public and the other one is private. $\innerproduct(\mathsf{pp}, x, \cm, v ; z)$ is the notation we will be using through out the paper, where $\mathsf{pp}$ is the public parameter consists of group description and generator, $x$ is a public vector and $\cm$ is the commitment of the private vector $z$ such that $\innp{x}{z} = v$.

 
%--------------------------------Protik's prelims--------------------------------
%\subsection{Codes}
%\paragraph{\textbf{Reed-Solomon Code:}} For positive integers $n,k$, finite field $\mathbb{F}$, and a vector $\eta = (\eta_1,\cdots ,\eta_n) \in \mathbb{F}_n$ of distinct field elements, the code $RS_{\mathbb{F},n,k,\eta}$ is the $[n,k,n-k+1]$ linear code over $\mathbb{F}$ that consists of all $n$-tuples $(p(\eta_1),...,p(\eta_n))$ where $p(\cdot)$ is a polynomial of degree $< k$ over $\mathbb{F}$.
%\dnote{Comments for Protik:\\
%1. Have spaces between paragraphs even in Latex. The PDF generated by Latex is usually beautiful and readable. The tex file can't be beautiful but should atleast be as readable as the PDF.\\
%2. I have already told you many times, and I am not going to leave till you use it :) Use macro for any notation that you use more than two times throughout the paper. (You will realize the use of it the day we decide change some notation in the middle of writing a paper.. But it is also a good practice to do it in general).\\
%3.Use \ ldots for ...\\
%4. You could use subsection* or subsubsection* instead of having a paragraph and using a textbf inside. (try both, what looks better depends on the cls file you use).}
%\paragraph{\textbf{Interleaved Code:}} Let $L\subset \mathbb{F}_n$ be an $[n,k,d]$ linear code over $\mathbb{F}$. We let $L^m$ denote the $[n,mk,d]$ (interleaved) code over $\mathbb{F}^m$ whose code words are all $m\times n$ matrices $U$ such that every row $U_i$ of $U$ satisfies $U_i\in L$. For $U\in L^m$ and $j\in[n]$, we denote by $U[j]$ the $j^{th}$ symbol (column) of $U$.
%\dnote{Have "th" in jth outside math mode.}
%
%\subsection{Interactive Oracle Proofs} The Interactive Oracle Proofs is the notion which combine both Interactive Proofs and Probabilistically Checkable Proofs, and also generalize the notion of the Interactive PCPs.
%\paragraph{} A $k$-round public-coin IOP has $k$ rounds of interaction. In the $i^{th}$ round of interaction, the verifier sends a uniformly random message $m_i$ to the prover; then the prover replies with a message $\pi_i$ to the verifier. After $k$ rounds of interaction, the verifier makes some queries to the oracles it received and either accepts or rejects.
%\dnote{Have at least the main definitions in the Definition environment.}
%\paragraph{} An IOP system for a relation $\mathcal{R}$ with round complexity $k$ and soundness error $\epsilon$ is a pair $(P, V )$, where $P, V$ are probabilistic algorithms, that satisfies the following properties:
%\paragraph{\textit{Completeness:}}  For every instance-witness pair $(x,w)$ in the relation $\mathcal{R}, (P (x, w), V (x))$ is a $k(n)$-round interactive oracle protocol with accepting probability 1.
%\paragraph{\textit{Soundness:}} For every instance $x \notin \mathcal{L(R)}$ and unbounded malicious prover $P^*, (P^*, V (x))$ is a $k(n)$-round interactive oracle protocol with accepting probability at most $\epsilon(n)$.
%\subsection{Zero-Knowledge} 
%\paragraph{\textbf{Interactive Argument Systems:}} A pair of PPT(Probabilistic Polynomial Time) interactive machines $<P, V>$ is called an interactive proof system for a language $\mathcal{L}$ if there exists a negligible function $negl(\cdot)$ such that the following two conditions hold:
%\dnote{1. have space before a ( or any other bracket.\\
%2. Use \ langle and \ rangle instead of $<$ and $>$ when using it as brackets.
%3. You can have negl in mathsf, it would look better (have a macro for this too!)}
%\begin{itemize}
%	\item[(1)] \textit{Completeness:} For every $x\in \mathcal{L}$ there exists a string $w$ such that for every $z \in \{0,1\}^*$,
%$Pr[<P(x,w),V(x,z)>=1] \geq 1-negl(|x|)$.
%	\item[(2)] \textit{Soundness:} For every $x \notin \mathcal{L}$, every interactive PPT machine $P^*$, and every $w,z\in \{0,1\}^*$ $Pr[<P^*(x,w),V(x,z)>=1]\leq negl(|x|)$ 
%\end{itemize}
%\paragraph{\textbf{Zero Knowledge:}} Let$<P,V>$ be an interactive proof system for some language $\mathcal{L}$. We say that $<P,V>$ is computational zero-knowledge with respect to an auxiliary input if for every PPT interactive machine $V^*$ there exists a PPT algorithm $S$, running in time polynomial in the length of its first input, such that $\{<P(x,w),V^*(x,z)>\}_{x\in \mathcal{L},w\in \mathcal{R}_x,z\in \{0,1\}^*}\approx_c \{<S(x,z)>\}_{x\in\mathcal{L},z\in\{0,1\}^*}$
%\subsection{Commitment schemes} 
%\paragraph{\textbf{Commitemnts:}} A non-interactive commitment scheme consists of a pair of probabilistic polynomial time algorithms $(Setup,Com)$. The setup algorithm $pp\leftarrow Setup(1^{\lambda})$ generates public parameters $pp$ for the scheme, for security parameter $\lambda$. The commitment algorithm $Com_{pp}$ defines a function $M_{pp} \times R_{pp} \rightarrow C_{pp}$ for message space $M_{pp}$, randomness space $R_{pp}$ and commitment space $C_{pp}$ determined by $pp$. For a message $x\in M_{pp}$, the algorithm draws $\delta \in_R  R_{pp}$ uniformly at random, and computes commitment $\com = Com_{pp}(x; \delta)$.\\
%For ease of notation we write $Com = Com_{pp}$.
%\dnote{All algorithm names in mathsf (macro for each). Eg. in the above paragraph, Setup, Com, ...}
%\paragraph{\textbf{Homomorphic Commitment:}} A homomorphic commitment scheme is a non-interactive commitment scheme such that $M_{pp},R_{pp}$ and $C_{pp}$ are all abelian groups, and for all $x_1,x_2 \in M_{pp}, \delta_1,\delta_2 \in R_{pp}$, we have $Com(x_1; \delta_1) + Com(x_2; \delta_2) = Com(x_1 + x_2; \delta_1 + \delta_2)$
%\dnote{Hiding and binding are the core properties of a commitment scheme, i.e., a definition of a commitment scheme includes the properties of hiding and binding. So bring them first. And just mention ``Hiding'' and ``Binding''.}
%\paragraph{\textbf{Hiding Commitment:}} A commitment scheme is said to be hiding if for all PPT adversaries $\Adv$ there exists a negligible function $\mu(\lambda)$ such that
%$$ |Pr[b=b'|pp\leftarrow Setup(1^{\lambda}); (x_0,x_1)\in M^2_{pp}\leftarrow \Adv(pp), b\in_R\{0,1\}, \delta \in_R R_{pp}, \com=Com(x_b;\delta), b'\leftarrow \Adv(pp,com)]-\frac{1}{2}|\leq \mu(\lambda)$$
%\paragraph{\textbf{Binding Commitment:}} A commitment scheme is said to be binding if for all PPT adversaries $\Adv$ there exists a negligible function $\mu$ such that 
%$$Pr[Com(x_0;\delta_0)=Com(x_1,\delta_1) \wedge x_0\neq x_1| pp\leftarrow Setup(1^{\lambda})x_0,x_1,\delta_0, \delta_1\leftarrow \Adv(pp)]\leq \mu(\lambda)$$
%\dnote{Have a subsection* with Pedersen commitment, and have the vector commitment also in the same part.}
%\paragraph{\textbf{Pedersen Commitment:}} $M_{pp}, R_{pp} = \mathbb{Z}_p, C_{pp} = \mathbb{G}$ of order $p$.\\
%$Setup : g, h \in_R \mathbb{G}$\\
%$Com(x,\delta)=(g^xh^{\delta})$
%\paragraph{\textbf{Pedersen Vector Commitment:}} $M_{pp}= \mathbb{Z}^n_p , R_{pp} = \mathbb{Z}_p, C_{pp}= \mathbb{G}$ with G of order p.\\ 
%$Setup: \vc{g}=(g_1,\cdots,g_n),h \in_R \mathbb{G}$\\
%$Com(\vc{x} = (x_1,\cdots,x_n);\delta) = h^r\vc{g}^{\vc{x}} = h^r \prod\limits_i g_i^{x_i} \in \mathbb{G}$
