\section{Zero-Knowledge}
We have three checks:
\begin{itemize}
	\item Interleaved Testing
	\item Linear Check
	\item Quadratic Check
\end{itemize}
Note that during the interleaved testing, $w$ is sent to the verifier, where $w$ is the linear combination of all the rows of the encoding matrix, which verifier cannot compute on his own. So, it is required to blind the vector $w$ by adding an additional vector which is a codeword.\\

For Linear check, verifier is receiving the polynomial $q(\cdot)$, and can evaluates in many points which he should not learn on his own, verifier should learn only $\sum\limits_{c\in[l]}q(\zeta_c)$. To hide this, we will add a polynomial $\qb(\cdot)$ such that $\sum\limits_{c\in[l]}\qb(\zeta_c)=0$ and later $q_j(\eta_k)$ is opened to the verifier, hide this we need to add another polynomial to each $q_j(\cdot)$, say $\qbj(\cdot)$ such that $\qbj(\zeta_c)=0$ $\forall c\in [l]$. To achieve this we will include one slice where each row but the $(m+1)th$ is encoding of zero vector. and in the $(m+1)th$ row is the encodig of a vector which sums to 0.\\

Similarly for quadratic also, we need to include one slice where each row  is the encoding of zero vector.

\subsection{Simulation for Zero-knowledge} Let $\tau_1, \tau_2, \tau_3$ be the transcripts of the interleaved check, linear check and quadratic check at the time of the execution of the protocol. where 
$$\tau_1=\{r_1,\tc, \gamma_1, w, Q_1, C_{Q_1}, \tU_{Q_1}, \tilde{\delta}_{Q_1}, \tilde{v}_{Q_1}\}$$
$$\tau_2= \{r_2, d_{1[h]}, q_1(\cdot), Q_2, \overline{q}_{1Q_2}, C_{Q_2}, U_{Q_2}, \delta_{Q_2}, v_{Q_2} \}$$
$$\tau_3= \{r_3, d_{2[h]}, \gamma_2, q_2(\cdot), Q_2, \overline{q}_{2Q_2}, C_{Q_2}, U_{Q_2}, \delta_{Q_2}, v_{Q_2} \}$$

But in our protocol we will be exectuing all the three protocols together and the final transcript will be:
$$\tau = \{r_1, r_2, r_3, \tc, d_{1[h]}, d_{2[h]}, \gamma_1, \gamma_2, w, q_1(\cdot), q_2(\cdot), Q_1, Q_2, \overline{q}_{1Q_2}, \overline{q}_{2Q_2}, C_Q, \tU_{Q_1}, U_{Q_2}, \tilde{\delta}_{Q_1}, \delta_{Q_2}, \tilde{v}_{Q_1}, v_{Q_2} \}$$
Let $\cS$ be the simulator. $\cS$ picks $r_1, r_2, r_3, \gamma_1, \gamma_2$ unifromly at random. \\
Define: $Q'_2=\{k: (j,k)\in Q_2\}$.
Let, $Q = Q_1\cup Q'_2$, $\cS$ picks $Q$ uniformly at random.
For our protocol, $|Q|=t$ and $Q_1\cap Q'_2=\phi$.\\
Corresponding to $Q$, $\cS$ chooses a block $\B$ i.e. $\{U[\cdot,\cdot,k]: k\in Q\}$ uniformly at random. \\
$\cS$ computes the commitment of $U[i,\cdot,k]$, $\forall i\in [p], k\in Q$ and define as $C_Q$. The commitment is being done using the randomness $\delta_Q$, chosen by $\cS$ randomly.
$$C_{ik}= \com(U[i,\cdot,k],\delta_{ik}), \forall i\in [p], k \in Q$$
and define $\tilde{\delta}_{Q_1}= \sum\limits_{i\in[p]} r_{1_i}\delta_{iQ_1}$.
$\cS$ generates $\tc$ in two parts $\tc_Q$ and $\tc_{\overline{Q}}$, where $\tc_Q=\{\tc_k:k\in Q\}$.\\
Define: $\tc_Q=\sum\limits_{i \in [p]} r_{1_i}\cdot C_{iQ}$. Since $\tc$ is the commitment of $\tU$, which should not reveal nothing about $\tU$ and therefore picking remaining components $\tc$ i.e. $\tc_{\overline{Q}}$ has the uniform distribution over the set of all output of commitments.\\
Define $\tU_{Q_1}= \sum\limits_{i\in [p]} r_{1_i}\cdot U[i,\cdot,Q_1]$.\\
Now we will describe how the simulator $\cS$ generates $w$, again it will be done in two parts: $w_Q, w_{\overline{Q}}$. \\
define $w_Q=\sum\limits_{j\in [m]} [\gamma_{1_j}\cdot (\sum\limits_{i\in[p]} r_{1_i}\cdot U[i,j,Q])]+ \tv_Q$.\\
Let $w'$ be the linear combination of the rows of $U$ along the $p$ and $m$ direction without blinding. As $w'$ is the encoding of the linear combination of the extended witness along the $p$ and $m$ direction and $\cS$ fixed the block $\B$ of size $t$, which gives that $\exists$ only one $w'$ which satisfies both the properties: 
i.e. $w'_k=\sum\limits_{j\in [m]} [\gamma_{1_j}\cdot (\sum\limits_{i\in[p]} r_{1_i}\cdot U[i,j,k])]$ $\forall k\in Q$ and $w'$ is the encoding of $\sum\limits_{j\in[m]}[\gamma_{1_j}\cdot(\sum\limits_{i\in[p]} r_{1_i}\cdot x_{ijk})]$, if $\vecx$ is the extended witness. So $w'$ has $t+l$ constraints, which fixes $w'$. Now for blinding $w=w'+v$, where $v$ is a random codeword, of which $\cS$ picks $t$ components uniformly at random say, $v_Q$. Among the remaining components $\cS$ can pick at most $l$ many randomly so that $v$ is a random codeword. So, $w=w'+v$ has the same distribution as $v$. So, for $w$ from remaining components, $\cS$ picks randomly $l$ many of them as $w_{\oQ}=w'_{\oQ}+v_{\oQ}$, has the same distribution as $v_{\oQ}$.\\
$q_1(\cdot)=\sum\limits_{j\in[m]} q_{1_j}(\cdot)+ q_{1_{blind}}(\cdot)$ and $q_{1_j}(\cdot)=\sum\limits_{i\in[p]}q_{1_{ij}}(\cdot)+\q1bj(\cdot)$\\
$\cS$ chooses a random polynomial $q_1(\cdot)$ of degree $<s+l-1$ such that $\sum\limits_{c\in[l]}q_1(\zeta_c)=\overline{r}^Tb$.\
From $r_2$, construct polynomials $r_{2_{ij}}(\cdot)$ of degree $<l$ such that $r_{2{ij}}(\zeta_k)=r_{2_{ijk}}$.\\
Set, $\overline{q}_1[k]_j=\sum\limits_{i\in[p]} r_{2_{ij}}(\eta_k)\cdot U_{ijk} + U[p+1,j,k]$ $(j,k)\in Q_2$ this gives that $\overline{q}_{1Q_2}$ and for all remaining values of $(j,k)\in Q_2$, choose $\oq_1[k]_j$ uniformly at random. Define: $d_{1[h]}=\com(\oq_{1}[h])$.\\
Similarly we have, $q_2(\cdot)=\sum\limits_{j\in[m]}\gamma_{3_j}\cdot q_{2_j}(\cdot) + q_{2_{blind}}(\cdot)$ and $q_{2_j}(\cdot) = \sum\limits_{i\in [p]} r_{3_i}\cdot q_{2_{ij}}(\cdot) + q_{2_{blind_j}}(\cdot)$.\\
$\cS$ picks a random polynomial $q_2(\cdot)$ of degree $<2s-1$ such that $q_2(\zeta_c)=0$ $\forall c\in [l]$. Now $\cS$ needs to construct $\oq_2$ and $d_{2[h]}$,
for $(j,k)\in Q_2$, set $\oq_2[k]_j=\sum\limits_{i\in[p]} r_{3_i}\cdot U[i,j,k] + U[p+1,j,k]$, this gives $\oq_{2Q_2}$ and for all remaining values of $(j,k)\in Q_2$, choose $\oq_2[k]_j$ uniformly at random. Define: $d_{2[h]}=\com(\oq_2[h])$.\\
We can see that $\cS$ can generate a transcript which is indistinguishable from an actual transcript.