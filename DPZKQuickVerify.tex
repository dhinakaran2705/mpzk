%\newcommand{\enc}{\mathsf{Enc}}

\subsection{Witness Encoding}\label{sec:witencoding}
We start by describing a randomized encoding of the prover witness $\wit\in \FF^N$. Let $p,m$ and
$s$ be integers such that $N=pms$. We canonically view the
witness $\wit$ 
as $p\times m\times s$ matrix with entries $\wit[i,j,k]$ for $i\in [p]$,
$j\in [m]$ and $k\in [s]$. The encoding is specified by an independence 
parameter $\bi$, integers $\ell := s+\bi$, $h>2m$, $n>2\ell$, and sequences
$\bm{\zeta},\bm{\eta},\bm{\alpha}$ of distinct points in $\FF$ with cardinality 
$\ell,n,h$ respectively. We write $\bm{\zeta}=(\zeta_1,\ldots,\zeta_\ell)$,
$\bm{\eta}=(\eta_1,\ldots,\eta_n)$ and $\bm{\alpha}=(\alpha_1,\ldots,\alpha_h)$. 
Next we define the interpolation domain $G$ as $G=\{(\alpha_j,\zeta_k): j\in[m],
k\in [\ell]\}$ and evaluation domain $H$ as $H=\{(\alpha_j,\eta_k): j\in [h],
k\in [n]\}$. Finally, we encode $\wit$ as follows and denote the below randomized computation as $\ewit\gets \enc(\wit)$.
 We may denote $\enc(\wit)$ as the random variable denoting the encodings of $\wit$:
\begin{enumerate}[{\rm (i)}]
\item First we embed $\wit$ into a $p\times m\times \ell$ matrix $\hat{\wit}$
where $\hat{\wit}[i,j,k]=\wit[i,j,k]$ for $k\leq s$, while the entries
$\hat{\wit}[i,j,k]$ for $k>s$ are sampled from $\FF$ uniformly at random.
\item We construct bivariate polynomials $Q^i(x,y)$ with $deg_x(Q)<m$ and
$deg_y(Q) $ $<\ell$ such that $Q^i$ interpolates the slice
$\hat{\wit}[i,\cdot,\cdot]$ on $G$, i.e,
$Q^i(\alpha_j,\zeta_k)=\hat{\wit}[i,j,k]$. 
\item Let $\ewit$ denote the $p\times h\times n$ matrix, where the slice
$\ewit[i,\cdot,\cdot]$ consists of evaluations of $Q^i$ on $H$, i.e,
$\ewit[i,j,k]=Q^i(\alpha_j,\eta_k)$ for $i\in [p], j\in [h]$ and $k\in [n]$.
Then $\ewit$ is a randomized encoding of $\wit$.
\end{enumerate}
 It is easily seen
that $\ewit[i,\cdot,\cdot]\in \rsc{\eta}{n,\ell}\otimes \rsc{\alpha}{h,m}$. We remark that the above
encoding can be computed using $O(N\log N)$ field operations (see Appendix for
details \commentA{missing section no.}).
%%  Computing the encoding in O(Nlog N) time: Move to Appendix
%\noindent{\em Efficiently computing the encoding}: Although the previous
%description of the encoding involves the bivariate polynomials, 
%the prover does not explicitly need to compute the bivariate polynomials to
%construct the encoding. We describe an efficient method to construct the
%encoding. Given an $m\times \ell$
%matrix $\matx$, the prover first computes polynomials $p_j$ for $j\in
%[m]$ as $p_j(y) := \ifft(\matx[j,\cdot], \bm{\zeta})$. Then it constructs a $m\times n$
%matrix $\maty$, where the $j^{th}$ row of $\maty$ is evaluation of $p_j$ on the set
%$\bm{\eta}$, i.e, $\maty[j,\cdot] := \fft(p_j, \bm{\eta})$. Next, the prover constructs
%polynomials $q_k$ for $k\in [n]$ by interpolating the column $\maty[\cdot,k]$ on
%$\bm{\alpha}^0 = (\alpha_1,\ldots,\alpha_m)$, i.e, $q_k(x) := \ifft(\maty[\cdot,k],
%\bm{\alpha}^0)$. It obtains the encoding $\enc(\matx)$ as the $h\times n$ matrix
%$\matz$ whose columns are evaluations of polynomials $q_k$ on the set $\bm{\eta}$, i.e,
%$\matz[\cdot,k]=\fft(q_k,\bm{\alpha})$. The above computation involves
%$O(mn\log(mn))$ operations in $\FF$ for each $m\times \ell$ matrix. Thus, computing $\enc(\wit)$ takes
%$O(pmn\log(mn))$ which is $O(N\log{N})$. We also remark that $\maty$ is a submatrix
%of $\matz$, and thus
%$p_j=\ifft((\matz[j,1],\ldots,\matz[j,\ell]),(\eta_1,\ldots,\eta_{\ell}))$ for $j\in
%[m]$. This allows us to consistently define polynomials $p_j$ for $m<j\leq h$ by
%$p_j=\ifft((\matz[j,1],\ldots,\matz[j,\ell]),(\eta_1,\ldots,\eta_{\ell}))$.
%%
The encoding $\enc$ satisfies the following {\em bounded independence} property:
\begin{lemma}[Bounded Independence]\label{lem:boundedindependence}
Let $B\subseteq [n]$ be a set of size $\bi$. Let $\mc{U}(p,h,b)$ denote the
set of $p\times h\times b$ matrices $\matx$ such
that $\matx[i,\cdot,k]$ is a codeword in $\rsc{\alpha}{h,m}$ for all $i\in
[p],k\in [\bi]$. Then for any $p\times m\times s$ matrix $\wit$, the random
variable $\ewit_B := \{\ewit[\cdot,\cdot,B]: \ewit\sample \enc(\wit)\}$ is
distributed uniformly on $\mc{U}(p,h,b)$.
\end{lemma}
We defer the proof of the above Lemma to the Appendix. \commentA{appendix number is missing}

\subsection{Codes and Matrices}\label{sec:codesandmatrices}
We now fix the notation for some of the codes that will be
frequently used throughout this section. We use $L_1$ and $L_2$ to denote codes
$\rsc{\eta}{n,\ell}$ and $\rsc{\alpha}{h,m}$ respectively. Let $\mc{C}_1 := \ric{L_1}{h}$ 
and $\mc{C}_2 :=\cic{L_2}{n}$ denote the interleaved codes of $L_1$ and $L_2$. In addition 
we use codes $L_3 := \rsc{\eta}{n,s+\ell}$, $L_4 := \rsc{\eta}{n,2\ell}$ and 
$L_5=\rsc{\alpha}{h,2m}$ to encode some intermediate computations in our protocols.
Let $\Lambda_1$ denote the matrix for the linear transformation that maps a vector $x\in \FF^\ell$ 
to the unique codeword $y$ in $L_1$ such that $y_i=x_i$ for $i\in [\ell]$. Thus $\Lambda_1$ is 
an $n\times \ell$ matrix. Let $\Lambda_2,\Lambda_3,\Lambda_4$ and $\Lambda_5$ be similar matrices
for the codes $L_2,L_3,L_4$ and $L_5$ respectively. We denote the
parity check matrices for $L_i$  by $\mc{H}_i$ for $i\in \{1,\ldots,5\}$. 
We notate the set of three dimensional $p\times h\times n$ matrices as $\mc{M}_{p,h,n}$ and
the set of two dimensional $h\times n$ matrices as $\mc{M}_{h\times n}$. We
assume standard distance metrics on the sets $\mc{M}_{p,h,n}$ and $\mc{M}_{h,n}$

\subsection{Commitments for Product Codewords}\label{sec:matrixcommitment}
We now discuss the commitment scheme
for matrices in $L_1\oplus L_2$. Similar scheme works for other product codes also. 
Note that a matrix $U\in L_1\oplus L_2$ is

completely determined by the submatrix $\overline{U}=\{U[j,k]: j\in [m], k\in [\ell]\}$.
Thus, it is sufficient to commit to the matrix $\overline{U}$. We commit to the
matrix $\overline{U}$ using a vector of commitments $\bm{c}=(c_1,\ldots,c_\ell)$
where $c_k=\comm(\overline{U}[\cdot,k])$ is the vector commitment for $k^{th}$
column of $\overline{U}$ for $k\in [\ell]$. 

\subsection{Oracle Construction}\label{sec:construct_oracle} 
Unlike prior IOP constructions such as \cite{ligero, aurora}, we additionally
obtain a homomorphic commitment on the encoded witness $\enc(\wit)$ and provide
oracle access to the commitment. Concretely, we use a
homomorphic vector commitment scheme $\comm$ with message space $\FF^m$,
commitment space $\GG$ and randomness space $\FF$. For all $(i,k)\in [p]\times
[n]$, we sample randomness $\delta_{ik}\sample \FF$, and obtain the commitment
$c_{ik}=\comm(V_{ik},\delta_{ik})$ for the vector 
$V_{ik}=(\ewit[i,1,k],\ldots,\ewit[i,m,k])\in \FF^m$. 
Finally we define $p\times n$ matrix $\comoracle$ as
$\comoracle[i,k]=c_{ik}$. We provide oracle access to $\comoracle$ where for a
query $Q\subseteq [n]$, the oracle responds with columns $\comoracle[\cdot,k]$ for
$k\in Q$. Note that $i^{th}$ row of the matrix $\comoracle$ commits to the

$i^{th}$ slice of $\ewit$, which is a codeword in $L_1\oplus L_2$. In contrast
to Section ~\ref{sec:matrixcommitment}, instead of

committing to its $\ell$ columns as above, we commit to all $n$ columns. This is
because the verifier cannot access all $\ell$ commitments to the first $\ell$ columns
 as it only has oracle access to $\comoracle$. 

\subsection{Well Formed Encodings}\label{sec:wellformedenc}
Let $\mc{W}$ denote the subset of $\mc{M}_{p,h,n}$
consisting of matrices $U$ such that $U[i,\cdot,\cdot]\in L_1\otimes L_2$ for all $i\in [p]$. 
We call an encoding $\ewit$ to be {\em well-formed} if $\ewit\in \mc{W}$. Note
that an encoding $\ewit\gets \enc(\wit)$ for any $\wit\in \FF^N$ is well formed. 
Let $\mc{W}_1$ denote the set of matrices
$U$ in $\mc{M}_{p,h,n}$ such that the $n$-length vector $U[i,j,\cdot]$ is a
codeword in $L_1$ for all $i,j$. Similarly let $\mc{W}_2$ denote the set of
matrices $U$ such that the $h$-length vector $U[i,\cdot,k]$ is a codeword in
$L_2$ for all $i,k$. It can be seen that $\mc{W}=\mc{W}_1\cap \mc{W}_2$. For $U^\ast\in \mc{M}_{p,h,n}$ define
$d(U^\ast,\mc{W}_i)=\min\{\Delta_i(U^\ast,U):U\in \mc{W}_i\}$ for $i=1,2$.

\subsection{Witness Decoding}\label{sec:witdecoding}
We describe a decoding procedure $\dec$ for obtaining a witness $\wit$ from an encoding
$\ewit$. Let $\ewit\in \mc{W}$ be a well formed encoding. Such an encoding can
be decoded slice by slice, i.e, for each $i\in [p]$, we interpolate bivariate
polynomial $Q^i\in \FF[x,y]$ with $deg_x(Q^i)<m$ and $deg_y(Q^i)<\ell$ such that
$Q^i$ interpolates $\ewit[i,\cdot,\cdot]$ on $H$. This can be accomplished using
standard algorithms. The decoded witness $\wit$ is then given by
$\wit[i,j,k]=Q^i(\alpha_j,\zeta_k)$. We extend the above decoding procedure to
recover from slightly malformed encodings. Let
$e_1<(n-\ell)/2$ and $e_2<(h-m)/2$. Let $\ewit^*\in \mc{M}_{p,h,n}$ be such
that $d(\ewit^*,\ewit_1)<e_1$ and $d(\ewit^*,\ewit_2)<e_2$ for some $\ewit_1\in
\mc{W}_1$ and $\ewit_2\in \mc{W}_2$. Let $E_1$ denote
the indices of the planes where $\ewit^*$ differs from $\ewit_1$ and 
$E_2$ denote the indices of the slabs where $\ewit^*$ differs from $\ewit_2$.
Let $F_1=[n]\backslash E_1$ and
$F_2=[h]\backslash E_2$. Note that each
slice $\ewit^*[i,\cdot,\cdot]$ satisfies
$d(\ewit^*[i,\cdot,\cdot],\mc{C}_1)<e_1$  and
$d(\ewit^*[i,\cdot,\cdot],\mc{C}_2)<e_2$. Since $e_1<(n-\ell)/2$ and
$e_2<(h-m)/2$, we conclude that $\ewit_1[i,\cdot,\cdot]$ and
$\ewit_1[i,\cdot,\cdot]$ are the unique codewords in $\mc{C}_1$ and $\mc{C}_2$
such that $d_1(\ewit[i,\cdot,\cdot],\ewit_1[i,\cdot,\cdot])<e_1$ and
$d_2(\ewit[i,\cdot,\cdot],\ewit_2[i,\cdot,\cdot])<e_2$. These codewords and thus
sets $F_1,F_2$ may be
determined using algorithms for decoding Reed Solomon codes. From Lemma ~\ref{lem:bicdecoding}, it follows that for all $i\in [p]$, there exists $U^i\in L_1\oplus L_2$ such
that $U^i[j,k]=\ewit^*[i,j,k]$ for $(j,k)\in F_2\times F_1$. We define the
``correction'' of $\ewit^*$ as $\ewit$ where
$\ewit[i,j,k]=U^i[j,k]$. Finally, we define the decoding $\dec(\ewit^*) =
\dec(\ewit)$.
.\nnote{Provide reference to Reed Solomon Decoding}


\subsection{Linear Check Protocol}\label{sec:lincheck}
In this section, we describe an IPCP that allows a prover to prove knowledge of
witness $\wit\in \FF^N$ satisfying a linear constraint of the form $A\wit = b$
for some $A\in \FF^{M\times N}$ and $b\in \FF^M$. As before we veiw $\wit$ as
$p\times m\times s$ matrix where $N=pms$. As desribed previously in Sections
\ref{sec:witencoding} and \ref{sec:construct_oracle}, the prover obtains $\ewit\gets 
\enc(\wit)$ and $\comoracle\gets \comm(\ewit)$. We present the full protocol in
Figure \ref{fig:linearcheck}. First we describe the key ideas in the protocol
for an honest prover. We then discuss how to achieve soundness against an
adverserial prover.\smallskip

\noindent {\em Reduction to Inner Product}: To check $A\wit=b$, the verifier 
samples random $r\sample \FF^M$ and asks the prover to prove $r^TA\wit=r^Tb$.
 Both prover and verifier view the
vector $r^TA\in \FF^N$ as a $p\times m\times s$ matrix $R$ and interpolate
polynomials $R^i(x,y)$ for $i\in [p]$ with $deg_x(R^i)<m$ and $deg_y(R^i)<s$
satisfying $R^i(\alpha_j,\zeta_k)=R[i,j,k]$. Let $Q^i$, $i\in [p]$ denote the
polynomials used in interpolating (and encoding) witness $\wit$. Then, 
$\wit[i,j,k]=Q^i(\alpha_j,\zeta_k)$. The check $\innp{R}{\wit}=r^Tb$ reduces to
$\sum_{i,j,k}R^i(\alpha_j,\zeta_k).Q^i(\alpha_j,\zeta_k)=r^Tb$ where $i,j$ and
$k$ run over indices in $[p],[m]$ and $[s]$ respectively. The preceeding
identity can be succinctly
expressed as $\sum_{k\in [s]}p(\zeta_k)=r^Tb$, where $p(\cdot)$ denotes
the polynomial $\sum_{j=1}^m\sum_{i=1}^p
R^i(\alpha_j,\cdot)Q^i(\alpha_j,\cdot)$. Let $\zetabar$ denote the vector
$(\zeta_1,\ldots,\zeta_s)$ and let $p(\zetabar)$ denote the vector
$(p(\zeta_1),\ldots,p(\zeta_s))$. Then the polynomial identity reduces to the
inner product check $\innp{1^s}{p(\zetabar)}=r^Tb$.\smallskip  

\noindent {\em Intermediate Commitment}: 
We introduce an $h\times n$ matrix $P$
which serves as a bridge between the oracle $\comoracle$ and the eventual vector
$p(\zetabar)$. For $j\in [h]$, let $p_j$ denote the polynomial $\sum_{i\in
[p]}R^i(\alpha_j,\cdot)Q^i(\alpha_j,\cdot)$. We define the matrix $P$ by
$P[j,k]=p_j(\eta_k)$ for $j\in [h],k\in [n]$. Note that the matrix $P$ is in the
product of codes $\rsc{\eta}{n,s+\ell}$ and $\rsc{\alpha}{h,2m}$. We let the
prover commit to the matrix $P$, by sending column commitments for the $2m\times
(s+\ell)$ submatrix $\overline{P}$ of $P$ consisting of the first $2m$ rows and
the first $s+\ell$ columns of $P$. Let $c_1,\ldots,c_{s+\ell}$ denote the
commitments to columns of $\overline{P}$.\smallskip 

\noindent {\em Consistency of $P$ and $p(\zetabar)$}:
Let $\etabar$ denote the vector
$(\eta_1,\ldots,\eta_{s+\ell})$, and let $\Phi$ denote the $s\times (s+\ell)$
matrix such that $p(\zetabar)=\Phi p(\etabar)$. Further, observe that
$p(\etabar)=(\overline{P})^T[1^m]$, and thus
$p(\zetabar)=\Phi(\overline{P})^T[1^m]$. Now, we have
$\innp{1^s}{p(\zetabar)}=p(\zetabar)^T[1^s]=[1^m]^T\overline{P}\Phi^T[1^s]=\innp{1^m}{\overline{P}\varphi}$
where $\varphi=\Phi^T[1^s]$. Given commitments $c_1,\ldots,c_{s+\ell}$, the
commitment to $\overline{P}\varphi$ can be computed as
$\mathsf{cm}=\sum_{k=1}^{s+\ell}\varphi_kc_k$. Using an inner product argument
the prover can show that the commitment $\mathsf{cm}$ opens to vector $z$ such
that $\innp{1^m}{z}=r^Tb$. Binding property of the commitment ensures that
$z=\overline{P}\varphi$ with overwhelming probability. In the full protocol, 
the prover initially commits to a random $P_0\in \FF^m$ subject to $\innp{1^m}{P_0}=0$ and 
uses $\beta P_0 + \overline{P}\varphi$ as witness in the inner product protocol. Here 
$\beta\sample \FF\backslash \{0\}$ is randomly chosen by the verifier. This randomization
precludes the need for the inner product argument to be zero knowledge.\smallskip 

\noindent{\em Consistency of $\comoracle$ and $P$}: The verifier additionally
needs to determine if $P$ is correctly computed from the encoding $\ewit$
committed by the oracle $\comoracle$. The verifier proceeds to check the
consistency at randomly sampled positions $Q=\{(j_u,k_u): u\in [t]\}$ from
$[h]\times [n]$. It queries the oracle for the columns $\pi[\cdot,k_u]$ for
$u\in [t]$ and queries the prover for vectors $X_u=\ewit[\cdot,j_u,k_u]$ for
$u\in [t]$. For $u\in [t]$, let $f_u$ denote the unit vector in $\FF^h$ with $1$ in the position
$j_u$. The prover and the verifier run inner product arguments to establish the following:
\begin{enumerate}[{\rm 1.}]
\item $\innp{f_u}{P[\cdot,k_u]}=\sum_{i\in [p]}R^i(j_u,k_u)X_u[i]$ for $u\in
[t]$.  Note that for honestly computed $P$,
$\innp{f_u}{P[\cdot,k_u]}=P[j_u,k_u]=\sum_{i\in
[p]}R^i(\alpha_{j_u},\eta_{k_u})Q^i(\alpha_{j_u},\eta_{k_u})=\sum_{i\in
[p]}R^i(\alpha_{j_u},\eta_{k_u})\ewit[i,j_u,k_u]$. Thus the identity holds for
honestly computed $P$ and honest vectors $X_u=\ewit[\cdot,j_u,k_u]$. Now, the
verifier can compute the commitment $\mathsf{cm}_u$ to the vector $Z_u$ consisting of
the first $2m$ entries of the column $P[\cdot,k_u]$ using the
matrix $\Lambda_3$ (see Section ~\ref{sec:codesandmatrices}) as $\mathsf{cm}_u=\sum_{a\in [s+\ell]}\Lambda_3[a,k_u]c_k$. Next,
we observe that $\innp{f_u}{P[\cdot,k_u]}=\innp{f_u}{\Lambda_5
Z_u}=\innp{f_u^T\Lambda_5}{Z_u}$. In
the last formulation, the first vector is public and the commitment to the
second vector is known ($\mathsf{cm}_u$) and hence the prover and the verifier can
check the identity using the inner product argument.

\item $\innp{f_u}{W_{iu}}=X_u[i]$ for all $u\in [t],i\in
[p]$. Here $W_{iu}$ denotes the vector $\ewit[i,\cdot,k_u]$. Again, we write
$W_{iu}=\Lambda_2V_{iu}$ where $V_{iu}$ denotes the vector consisting of the
first $m$ entries of $W_{iu}$. We rewrite the preceeding inner product as
$\innp{f_u^T\Lambda_2}{V_{iu}}=X_u[i]$, which can be executed as the commitment
$\pi[i,k_u]$ of $V_{iu}$ is present as part of the oracle response. In fact, the checks for each
$u\in [t]$ can be aggregated, leading to one inner product check for each $u\in
[t]$.
\end{enumerate}

\noindent{\em Proximity Check for Oracle}: As we shall see, the soundness of the
preceeding checks depends on the oracle $\pi$ being ``close'' to a well formed
encoding. To check that, the verifier initially (before sending messages $r,Q$) sends a vector $\rho\sample
\FF^p$ and asks the prover to send commitments
$(\tilde{c}_1,\ldots,\tilde{c}_1)$ to $\tilde{U}=\sum_{i\in
[p]}r_i\ewit[i,\cdot,\cdot]$. It then checks for all $u\in [t]$ that $\sum_{a\in
[\ell]}\Omega_1[a,k_u]\tilde{c}_a = \sum_{i\in [p]}r_i\pi[i,k_u]$. It can be
seen that for an honest computation, both the commitments open to the vector
$\sum_{i\in [p]}\rho_iV_{iu}$ where $V_{iu}$ is as defined earlier.\smallskip

The complete linear check protocol is described in Figure \ref{fig:linearcheck}.
%the protocol $\agginnerproduct$ denotes the protocol 
%for veryfying inner products of several commited vectors with a common vector. 
%The completeness of the linear check protocol can be easily verified. We sketch the proof for its
%soundness, leaving the detailed proof to the Appendix.

\begin{lemma}[Soundness]\label{lem:linercheck_sound}
For all polynomially bounded provers $P^\ast$ and all $\pi\in \GG^{p\times n}$,
$A\in \FF^{M\times N}, b\in \FF^M$, there exists an expected polynomial time
extractor $\extr$ with rewinding access to transcript oracle $\mc{O}=\langle
P^\ast(\cdot),\verifier^\pi(\cdot)\rangle$ such that $\extr$ either breaks the 
commitment binding or outputs a witness with overwhelming probability whenever 
$P^\ast$ succeeds, i.e,
{\small
\begin{align*}
\condprob{\begin{array}{c}
\ewit=\open(\pi)\wedge \\
A\wit=b
\end{array}
}{
\begin{array}{c}
\sigma\sample \gen(\secparam) \\
\ewit\gets \extr^{\mc{O}}(\bm{x},\sigma) \\
\wit\gets \dec(\ewit)
\end{array}}\geq
\epsilon(P^\ast)-\kappa_{lc}(\secpar)
\end{align*}
}
where $\epsilon(P^\ast):= \condprob{\langle P^\ast(\bm{x},\sigma),\verifier^\pi(\bm{x},\sigma)\rangle=1}{\sigma\sample \gen(\secparam)}$ denotes the success probability of $P^\ast$, $\kappa_{lc}$ denotes a negligible function, and $\bm{x}$ denotes the tuple $(A,b,M,N)$.
\end{lemma}
\begin{proof}[Proof-Sketch]
Suppose the oracle $\pi$ commits to $\ewit$ such that $\wit=\dec(\ewit)$ does
not satisfy $A\wit=b$.  In a formal proof, $\ewit$ would be the ``extracted''
witness which opens to the oracle $\pi$. The proximity check ensures that for
$e<d_1/3$, $d(\ewit,\mc{W}_1)<e$ and $\ewit\in \mc{W}_2)$ with probability $\approx 1-(1-e/n)^t$.
Let $\ewit_{\rm hon}$ an encoding of $\wit$ such that $d_1(\ewit,\ewit_{\rm
hon})<e$ (see the detailed proof in the Appendix for existence of such an
encoding). Let $P_{\rm hon}$ denote honestly computed $P$ matrix from
$\ewit_{\rm hon}$. If the adverserial prover commits to a matrix $P_{\rm adv}$
such that $P_{\rm adv}=P_{\rm hon}$, it fails the inner product check, as
$r^TAw\neq r^Tb$. If it commits to $P_{\rm adv}\neq P_{\rm hon}$, it fails the
consistency checks with overwhelming probability. To see this consider the
adversarial provers' success probability for the query point $(j_u,k_u)$. Let
$E\subseteq [n]$ denote the indices of planes where $\ewit$ and $\ewit_{\rm
hon}$ differ. The prover opens the vector $X_u=\ewit[\cdot,j_u,k_u]$ (unless it breaks the
soundness of inner product protocol, or binding of the commitment scheme). For
$k_u\not\in E$, we see that to succeed in the consistency check we must have: 
\[ P_{\rm adv}[j_u,k_u]=\sum_{i=1}^p
R^i(\alpha_{j_u},\eta_{k_u})\ewit[i,j_u,k_u]=P_{\rm hon}[j_u,k_u] \]
Let $E'$ be the column indices where $P_{\rm adv}$ and $P_{\rm hon}$ differ.
Then the above check succeeds if (i) $k_u\not\in E'\backslash E$, or (ii) $j_u$
is the common root of distinct $m$ degree polynomials corresponding to columns
$P_{\rm adv}[\cdot,k_u]$ and $P_{\rm adv}[\cdot,k_u]$. In either case, adversary
fails with constant probability, and hence it's success probability is
negligible over $t=O(\secpar)$ checks.
\end{proof}

\begin{figure}[t!]
%\centering
\begin{framed}
\noindent{$\linearcheck(\mathsf{pp},A\in \mc{M}_{M,N},b\in \FF^M,[\pi];\ewit)$}:

\noindent{\bf Relation}: $\ewit=\open(\pi)\wedge A\wit=b$ for $\wit=\dec(\ewit)$.

\begin{enumerate}[{\rm 1.}]
\item $\verifier\rightarrow\prover$: $\rho\sample \FF^p$.
\item $\prover$ computes: $\tilde{U}=\sum_{i\in [p]}\rho_i\ewit[i,\cdot,\cdot]$, 
commitments $\tilde{c}_1,\ldots,\tilde{c}_\ell$ as in Section ~\ref{sec:matrixcommitment}.
\item $\prover\rightarrow\verifier$: $\tilde{\bm{c}}=(\tilde{c}_1,\ldots,\tilde{c}_\ell)$.
\item $\verifier\rightarrow\prover$: $r\sample \FF^N$.
\item $\prover\leftrightarrow\verifier$ compute: Polynomials $R^i$, $i\in [p]$ interpolating $R=r^TA$
as in Section ~\ref{sec:lincheck}. 
\item $\prover$ computes: Matrix $P$ from $R$ and $\ewit$ as described in Section ~\ref{sec:lincheck}. Samples $P_0\sample \FF^m$, $\omega_0\sample \FF$ and $c_0\gets \comm(P_0,\omega_0)$.
Computes commitments $c_1,\ldots,c_{s+\ell}$ form $P$.
\item $\prover\rightarrow\verifier$: $c_0,c_1,\ldots,c_{s+\ell}$.
\item $\verifier\rightarrow\prover$: $Q=\{(j_u,k_u):u\in [t]\}$ for $(j_u,k_u)\sample [h]\times [n]$ for $u\in [t]$.
\item $\verifier\rightarrow\pi$: $\{k_u:u\in [t]\}$.
\item $\prover\rightarrow\verifier$: $X_u=\ewit[\cdot,j_u,k_u]$ for $u\in [t]$.
\item $\pi\rightarrow\verifier$: $\pi[\cdot,k_u]$ for $u\in [t]$.
\item $\verifier\rightarrow\prover$: $\delta\sample \FF^p$, $\beta\sample \FF\backslash \{0\}$. 
\item $\prover$ and $\verifier$ run inner product arguments to check:
\begin{enumerate}
\item $\innerproduct(\mathsf{pp},f_u^T\Lambda_5,\mathsf{cm}_u,v_u;\overline{P}[\cdot,k_u])$ 
for $u\in [t]$ where $\mathsf{cm}_u=\sum_{a=1}^{s+\ell}\Lambda_3[a,k_u]c_a$, 
$v_u=\sum_{i=1}^pR^i(\alpha_{j_u},\eta_{k_u})X_u[i]$ (check consistency of $P$ with $\pi$).
\item $\innerproduct(\mathsf{pp},1^m,\mathsf{cm},r^Tb;z)$ where $z=\beta P_0+\overline{P}\varphi$ and $\mathsf{cm}=\beta c_0+\sum_{a=1}^{s+\ell}\varphi_ac_a$ (check the condition $r^TAw=r^Tb$).
\item $\innerproduct(\mathsf{pp},f_u^T\Lambda_2,C_u,\innp{\delta}{X_u})$ for $u\in [t]$ 
where $C_u=\sum_{i=1}^p\delta_i\pi[i,k_u]$ (consistency of $X_u$ with $\pi$). 
\end{enumerate}
\item $\verifier$ checks: $\sum_{a=1}^\ell\Lambda_1[a,k_u]\tilde{c}_a=\sum_{i=1}^p\rho_i\pi[i,k_u]$ for $u\in [t]$ (check proximity of $\ewit$ to $\mc{W}_1$).
\end{enumerate}
\end{framed}
\caption{Linear Check Protocol}
\label{fig:linearcheck}
\end{figure}


\subsection{Quadratic Check Protocol}
We now describe the IPCP which allows a prover to prove knowledge of vectors
$\wit_x$, $\wit_y$ and $\wit_z$ in $\FF^N$, satisfying $\wit_x\circ \wit_y =
\wit_z$. Once again, the protocol requires the prover to construct encodings
$\ewit_x=\enc(\wit_x)$, $\ewit_y=\enc(\wit_y)$ and $\ewit_z=\enc(\wit_z)$ as
described in Section \ref{sec:witencoding}. Thereafter, the prover uses
commitment scheme $\comm$ to commit to these encodings as $\comoracle_x =
\comm(\ewit_x)$, $\comoracle_y = \comm(\ewit_y)$ and $\comoracle_z = \comm(\ewit_z)$. 
The prover forms the oracle $\pi\in \GG^{3p\times n}$ by vertically stacking the
$p\times n$ matrices $\comoracle_x,\comoracle_y$ and $\comoracle_z$. As before,
for a query $Q\subseteq [n]$, the oracle answers with columns $\pi[\cdot,k]$ for
$k\in Q$. The columns returned by the oracle can be parsed into constituent columns 
$\comoracle_x[\cdot,k]$, $\comoracle_y[\cdot,k]$ and $\comoracle_z[\cdot,k]$
canonically. We again discuss the key ingredients of the protocol.

\noindent{\em Probabilistic Reduction}: Let $Q^i_x,Q^i_y$ and $Q^i_z, i\in [p]$ be the
polynomials interpolating the $i^{th}$ slices of $\wit_x$, $\wit_y$ and $\wit_z$
 as in Section \ref{sec:witencoding}. Then for vectors $\wit_x,\wit_y,\wit_z$ satisfying
$\wit_x\circ \wit_y=\wit_z$, the polynomials $Q^i=Q^i_x\cdot Q^i_y - Q^z_i$ interpolate
$\bm{0}^{m\times s}$ on the set $\{(\alpha_j,\zeta_k):j\in [m],k\in [s]\}$ for all $i\in [p]$. This can be probabilistically
checked by checking that the polynomial $F := \sum_{i\in [p]}r_iQ^i$ interpolates
$\bm{0}^{m\times s}$ on the above set for randomly sampled $r\in \FF^p$. Once again, we
ask the prover to ``commit'' to $F$ using a tamper resistant structure, like a codeword,
which enables the verifier to check the aforementioned condition, as well as to
ensure that the commitment is consistent with oracle replies and prior
messages.

\noindent{\em Reduction to Inner Products}: The prover computes 
$h\times n$ matrix $P$ given by $P[j,k]=F(\alpha_j,\eta_k)$. It commits to $P$
using commitments $(c_1,\ldots,c_{2\ell})$ to the first $2\ell$ columns of $P$.
Note that each row of $P$ commits to univariate component polynomials
$F(\alpha_j,\cdot)$ of $F$ via their evaluations of $\bm{\eta}$. To check that
$F$ interpolates $\bm{0}^{m\times s}$ on the points
$\{(\alpha_j,\zeta_k)\}_{j\in [m],k\in [s]}$, the verifier checks that
$p(\cdot) := \sum_{j\in [m]}\gamma_jF(\alpha_j,\cdot)$ interpolates $\bm{0}^s$ on
$\overline{\bm{\zeta}}$ for randomly sampled $\gamma=(\gamma_1,\ldots,\gamma_m)\in \FF^m$.
Again, the verifier checks $p(\overline{\bm{\zeta}})=\bm{0}^s$ via the inner product
check $\innp{\tau}{p(\overline{\bm{\zeta}})}=0$ for a random $\tau\in \FF^s$. As in the
linear check protocol, using $p(\overline{\bm{\zeta}})=\Phi p(\overline{\bm{\eta}})$, we
get the following inner product check
$\innp{(\gamma,0^{h-m})}{\overline{P}\varphi}=0$ where $\varphi=\Phi^T\tau$. 
The commitment to the vector $\overline{P}\varphi$ can be homomorphically computed
from $c_1,\ldots,c_{2\ell}$.

\noindent{\em Checking consistency with Oracle}: As in the linear check, the
verifier uniformly and independently samples $(j_u,k_u)\in [h]\times [n]$ for
$u\in [t]$, and queries the oracle $\pi$ for columns $\pi[\cdot,k_u]$. Let
$\pi_x[\cdot,k_u]$, $\pi_y[\cdot,k_u]$ and $\pi_z[\cdot,k_u]$ denote the parse
of $\pi[\cdot,k_u]$ into commitments corresponding to $\ewit_x,\ewit_y$ and
$\ewit_z$ respectively. Further, the verifier asks prover for vectors
$\ewit_x[\cdot,j_u,k_u]$, $\ewit_y[\cdot,j_u,k_u]$ and $\ewit_z[\cdot,j_u,k_u]$
for $u\in [t]$. The verifier then checks the following:
\begin{enumerate}[{\rm (i)}]
\item For all $u\in [t]$: $P[j_u,k_u]=\sum_{i\in
[p]}r_i(\ewit_x[i,j_u,k_u]\cdot\ewit_y[i,j_u,k_u]-\ewit_z[i,j_u,k_u])$.
\item Checks that vectors $\ewit_x[\cdot,j_u,k_u]$ are consistent with
commitments $\pi_x[\cdot,k_u]$ as in linear check protocol. Similar checks are
made for $\ewit_y[\cdot,j_u,k_u]$ and $\ewit_z[\cdot,j_u,k_u]$.
\end{enumerate}
We present the full protocol in Figure \ref{fig:quadcheck}. The completeness of
the protocol can again be verified by direct calculation. We state the soundness
of the protocol below:

\begin{lemma}[Soundness]\label{lem:quadcheck_sound}
For all polynomially bounded provers $P^\ast$ and all $\pi\in \GG^{3p\times n}$,
there exists an expected polynomial time extractor $\extr$ with rewinding access
to the transcript oracle $\mc{O}=\innp{P^\ast(\cdot)}{\verifier^{\pi}(\cdot)}$
such that either $\extr$ breaks the commitment binding, or it outputs a witness
with overwhelming probability whenever $P^\ast$ succeeds, i.e,
{\small
\begin{align*}
\condprob{
\begin{array}{c}
{[}\ewit_x||\ewit_y||\ewit_z{]}=\open(\pi)\wedge \\
\wit_z=\wit_x\circ\wit_y
\end{array}
}{
\begin{array}{c}
\sigma\sample \gen(\secparam) \\
{[}\ewit_x||\ewit_y||\ewit_z{]}\sample \extr^{\mc{O}}(\sigma)\\
\wit_a=\dec(\ewit_a), a\in \{x,y,z\}
\end{array}
}\geq \epsilon(P^\ast) - \kappa_{\rm qd}(\secpar)
\end{align*}
}
for some negligible function $\kappa_{qd}$. In the above, $\epsilon(P^\ast)$
denotes the success probability of the prover $P^\ast$ as before.
\end{lemma}
\begin{proof}
The proof is similar to the proof of the linear check protocol. Using similar
arguments, one can show that the above Lemma holds with:
{\small
\begin{equation*}
\kappa_{qd}(\secpar) := \left(1-\frac{e}{n}\right)^t +
\left(\frac{2m}{h}+\left(1-\frac{2m}{h}\right)\left(\frac{2\ell+e}{n}\right)\right)^t
+ \frac{O(|C|)}{|\FF|}
\end{equation*}
}
\end{proof}

\subsection{Zero Knowledge}
We now prove protocols $\linearcheck$ and $\quadcheck$ to be honest verifier zero knowledge by
designing simulators for them. We infact simulate ``extended'' view of the
verifier which includes
the witnesses for inner product protocols consisting of the committed vector 
and commitment randomness. It is clear then, that the simulation can be
completed by running the inner product argument on these simulated witness
vectors. We describe the view of the verifier in the linear check protocol with
the aforementioned extensions. We decompose the view as:

\noindent {\bf Verifier Randomness}: Vector $r\in \FF^N$ in Step 1,
$\{j_u,k_u\}_{u\in [t]}$, $\beta\in \FF_\ast$ in Step 5, $\tau,\delta$ as
part of $\proximityTwoD$ subprotocol in Step 10, $\rho\sample \FF^p$ as the
random vector for compressing in subprotocol $\proximityThreeD$ in Step 15,
$\tilde{\tau},\tilde{\delta}$ for the second invocation of $\proximityTwoD$ from within
$\proximityThreeD$. We
do not include the query positions as part of the subprotocol $\proximityThreeD$
as we assume that the same query positions sampled in Step 5 are used there.
Summarizing, the verifier randomness consists of $r,\{j_u,k_u\}_{u\in
[t]},\beta,\tau,\delta,\rho,\tilde{\tau},\tilde{\delta}$.

\noindent {\bf Commitments}: Commitment $c_0$ to the random codeword sampled in Step
3(d), commitments $c_1,\ldots,c_{s+\ell}$ to the first $s+\ell$ columns of the
matrix $P$, commitment $d_0$ for random vector $u_0$ used in $\proximityTwoD$
subprotocol in Step 10, commitments $\tilde{c}_1,\ldots,\tilde{c}_{\ell}$ as
part of $\proximityThreeD$ protocol in Step 15, and commitment $\tilde{d}_0$ to
the random codeword in the invocation of $\proximityTwoD$ from within
$\proximityThreeD$ in step 15. Additionally, the view contains commitments
$\pi[\cdot,k_u]$ for $u\in [t]$ as part of oracle query response. Summarizing,
the view consists of commitments $c_0,c_1,\ldots,c_{s+\ell},d_0$, 
$\tilde{c}_1,\ldots,\tilde{c}_{\ell},\tilde{d}_0,\{\pi[\cdot,k_u]\}_{u\in [t]}$

\noindent {\bf Commitment Randomness}: We include randomness used to compute certain
commitments as part of the extended view. We include $\nu=\nu_0+\sum_{a\in
[s+\ell]}\mu_a\omega_a$ for the vector $z$ in the subprotocol
$\proximityTwoD$ in Step 10 (here $\mu=\mc{T}\tau$),
$\omega=\beta\omega_0+\sum_{a\in [s+\ell]}\varphi_ac_a$ for inner product in
Step 11, $\chi_u=\sum_{a\in [s+\ell]}T[a,k_u]c_a$ for $u\in [t]$ for the inner
products in Step 13, $\{O[\cdot,k_u]\}_{u\in [t]}$ for aggregate inner product
arguments in Step 14, $\tilde{\nu}=\tilde{\nu}_0+\sum_{a\in
[\ell]}\tilde{\mu}_a\tilde{c}_a$ for the vector $\tilde{z}$ in the
$\proximityTwoD$ protocol called as part of $\proximityThreeD$ protocol in Step
15. Summarizing, the view includes $\nu,\omega,\{\chi_u\}_{u\in
[t]},\{O[\cdot,k_u]\}_{u\in [t]},\tilde{\nu}$.

\noindent {\bf Witness related vectors}: We describe various vectors derived from
witness encoding provided to the verifier. Vectors $X_u=\ewit[\cdot,j_u,k_u]$
for $u\in [t]$ in Step 6, the vector $z=u_0 + \overline{P}\mu$ ($\mu=\mc{T}\tau$) as
part of view of the subprotocol $\proximityTwoD$ in Step 10, the vector
$z'=\beta P_0+\overline{P}\varphi$ as the witness to the inner product check in Step
11, vectors $P[\cdot,k_u]$ for $u\in [t]$ as witnesses to inner product checks
in Step 13, matrices $\ewit[\cdot,\cdot,k_u]$ for $u\in [t]$ as witnesses to
aggregate inner product checks in Step 14, and finally the vector
$\tilde{z}=\tilde{u}_0 + \sum_{a\in [\ell]}\tilde{\mu}_a\tilde{c}_a$ as part of
protocol $\proximityTwoD$ from within $\proximityThreeD$ in Step 15. We drop
$\{X_u\}_{u\in [t]}$ and $\{P[\cdot,k_u]\}_{u\in [t]}$ from the view as these
can be derived from $\ewit[\cdot,\cdot,k_u]$ and $r$. Thus, the vectors in the
view consist of: $z,z',\{\ewit[\cdot,\cdot,k_u]\}_{u\in [t]},\tilde{z}$.

Next we describe a simulator that outputs a view indistinguishable from the
above view.

\noindent{\bf Simulator}: The simulator outputs $r$, $\{j_u,k_u\}_{u\in [t]}$,
$\beta$, $\tau,\delta$, $\rho$, $\tilde{\tau},\tilde{\delta}$ by uniformly and
independently sampling them from their respective domains, as in the honest
execution of the protocol. Simulator also outputs $z,\tilde{z}$ uniformly from
$L_2$, and $z'$ uniformly from $\dashL_2$ satisfying $\sum_{j\in [m]}z'[j]=0$ . It outputs
$\ewit[\cdot,\cdot,k_u]$ uniformly such that each plane has columns as codewords
in $L_2$. 
Next, the simulator outputs $\omega,\nu,\tilde{\nu}$
and $\chi_1,\ldots,\chi_t$, $\{O[\cdot,k_u]\}_{u\in [t]}$ choosing them randomly and
independently from $\FF$. Finally, the simulator outputs
$c_0,d_0,\ldots,c_{s+\ell}$ and $\tilde{d}_0,\tilde{c}_1,\ldots,\tilde{c}_\ell$ choosing 
them uniformly from $\GG$ subject to the following constraints:
$d_0 + \sum_{a=1}^{s+\ell}\mu_ac_a = \comm(z,\nu)$,
$c_0 + \sum_{a=1}^{s+\ell}\varphi_ac_a = \comm(z',\omega)$,
$\sum_{a=1}^{s+\ell}T[a,k_u]c_a = \comm(P[\cdot,k_u],\chi_u)$ for $u\in [t]$,
$\sum_{a=1}^{\ell}\mc{T}[a,k_u]\tilde{c}_a = \comm\big(\sum_{i\in
[p]}\tilde{U}[\cdot,k_u],\tilde{O}[\cdot, k_u]\big)$ for $u\in [t]$,
$\beta\tilde{d}_0 + \sum_{a=1}^{\ell}\tilde{\mu}_a\tilde{c}_a =
\comm(\tilde{z},\tilde{\nu})$. 

\begin{lemma}\label{lem:simlincheck}
The output of the above simulator is perfectly indistinguishable
from the extended view of the verifier in honest execution of the protocol
$\linearcheck$ for $t\leq \bi$.
\end{lemma}
We defer the proof of the correctness of the simulation to Appendix.
We omit the simulation for the quadratic check protocol, as it is very similar
to the linear check. One key difference we highlight is that we do not need to
randomize the vector $\overline{P}\varphi$, the witness in the inner product check in
Step 10 (and part of the extended view), as in the honest execution of the
protocol, $\overline{P}\varphi$ is the unique codeword $z$ of $L_2$ with $z[j]=0$ for
all $j\in [m]$. We state the lemma formally, skipping the proof.

\begin{lemma}\label{lem:simquadcheck}
There exists an efficient simulator $\simulator$ whose output is perfectly
indistinguishable from the extended view of the verifier in the honest execution
of the protocol $\quadcheck$ for $t\leq \bi$.
\end{lemma}


\subsection{Extension to DPZK}
We now describe variants of the protocols discussed previously when the witness
is shared among several provers. We assume that there are $K$ provers
$P_1,\ldots,P_K$. For $\xi\in [K]$, let $\shr{\wit}$ denote the prover
$\distprover$'s share of the witness $\wit$. We assume that the sharing is additive,
i.e, $\sum_{\xi\in [K]}\shr{\wit}=\wit$. When denoting witnesses to certain
protocols, we use the $[[\cdot]]$ to denote that the witness is additively
shared among the provers, i.e, notation $[[x]]$ in the witness list of the
protocol denotes that the provers have shares $\shr{x}$ of $x$. We assume that
there is a designated party $\Ag$ which aggregates the messages received from
provers $P_1,\ldots,P_K$ and constructs the message to be sent to the verifier
$\verifier$. The verifier's  messages are assumed to be available to every
prover through a broadcast channel. Finally, we mention that aggregator's role
is conceptual, and may be played by one of the provers. We proceed to describe
distributed versions of the key subprotocols.

\noindent{\bf Distributed Oracle Setup}: In distributed setting, each prover
$\distprover$ encodes his share $\shr{\wit}$ as $\shr{\ewit}=\enc(\shr{\wit})$
and computes the commitment $\shr{\comoracle}=\comm(\shr{\ewit})$. The provers
then share $\shr{\comoracle}$ with the aggregator $\Ag$ which sets the oracle
$\pi$ as $\pi := \combine(\shr{\comoracle})$.  

\noindent{\bf Distributed Proximity Test}: The provers jointly prove that 
the oracle is well formed as follows: On receiving the verifier’s challenge 
$r\in\FF^p$ on broadcast channel, the prover $\distprover$ locally computes
$\shr{\tilde{U}}=\sum_{i\in [p]}r_i\shr{\ewit}[i,\cdot,\cdot]$, commitments
$\shr{\tilde{c}_k}=\sum_{i\in [p]}\shr{\comoracle}[i,k]$ for $k\in [\ell]$. They
send the shares of the commitments to the aggregator, who computes
$(\tilde{c}_1,\ldots,\tilde{c}_\ell)=\combine(\shr{\tilde{c}_1},\ldots,\shr{\tilde{c}_\ell})$
and forwards these to the verifier. Next, the provers jointly prove that
$\tilde{c}_1,\ldots,\tilde{c}_\ell$ corresponds to a matrix $\overline{U}$ such
that $\overline{U}\mc{T}\in \mc{C}_2$. This is done via distributed variant of
membership protocol that we describe next.  

\noindent{\bf Distributed Membership Test}: 
This protocol reduces to each prover responding to verifier’s
challenge on their share, as in the single    prover setting. The prover
responses are aggregated to compute the response to    the verifier. The
complete protocol appears in Figure \ref{fig:distprox2d}. In Figure
\ref{fig:distprox2d}, we note that the aggregator obtains the witness to the
inner product protocol in step 7, and hence does not need to interact further
with the provers. 

\noindent{\bf Distributed Linear Test}: We provide the
complete distributed protocol in Figure \ref{fig:distlincheck}. Here we
highlight key adaptations from the single prover variant. First we assume
that the provers have a share of the vector $0^h$ (as part of obtaining
shares of the extended witness).\pnote{How to get shares of zero in malicious secure way?} In response to verifier’s challenge $r\in
\FF^M$, each prover locally computes $R=r^TA$ and the associated polynomials
$R^i$, $i\in [p]$. Since, the computation of the $P$ matrix is a linear
operation, each prover obtains a share $\shr{P}$ of the $P$ matrix by locally
computing on their share of the witness. The provers compute commitments to the
columns of their share of the $P$ matrix, and send those to the aggregator. The
aggregator combines the shares to obtain the commitment to the $P$ matrix.
Provers can jointly prove that $P$ matrix is a codeword in the product code
using the distributed membership protocol as above. Similarly, the provers can
send their shares of vectors $\shr{X_u}=\shr{\ewit}[\cdot,j_u,k_u]$ for $u\in
[t]$, required for consitency    checks. Due to the bounded independence
property, for $t\leq \bi$, these shares    do not leak. The only point of
departure is the shares of $z=\beta P_0 + \overline{P}\varphi$. The
randomization by a random codeword $P_0\in L_2$ such that $\sum_{j\in [m]}
P_0[j]=0$ was based on the distribution of the vector $\overline{P}\varphi$
in an honest execution of the protocol for a witness satisfying
$r^TA\wit=r^Tb$. However, individual shares may not satisfy the preceeding
condition, and hence the provers further add a share of $0^h$ to the share
$\beta\shr{P}_0 + \shr{\overline{P}}\varphi$. This allows the aggregator $\Ag$
to obtain witnesses for all the inner product protocols that it runs with the
verifier.  

\noindent{\bf Distributed Quadratic Check}: This is the only protocol
whose    distributed variant requires an additional interaction among the
provers. Recall    that in response to the verifier’s challenge $r\in \FF^m$,
the provers need to    compute the matrix $P$ given by:
\begin{align*}
P[j,k] & =\sum_{i\in
[p]}r_i\big(Q_x^i(\alpha_j,\eta_k).Q_y^i(\alpha_j,\eta_k)-Q_z^i(\alpha_j,\eta_k)\big)\\    
& = \sum_{i\in [p]}r_i(\ewit_x[i,j,k].\ewit_y[i,j,k] - \ewit_z[i,j,k])
\end{align*}    
In the above, the provers have additive shares of $\ewit_x$ and
$\ewit_y$, and so they peformn an MPC with $O(N)$ multiplication gates and
depth $1$, to obtain additive shares of $\ewit_x[i,j,k].\ewit_y[i,j,k]$.
Concretely, we assume an MPC $\mathsf{Mult}$    with following input/output for
a prover $\distprover$:     
\begin{align*}    
\shr{\ewit_x.\ewit_y}\leftarrow \mathsf{Mult}(\shr{\ewit_x},\shr{\ewit_y})    
\end{align*}    
Thereafter, each
prover obtains a share of matrix $P$, and the remaining protocol proceeds as
the distributed linear check protocol, except that we do not need to send the
shares $\shr{\overline{P}}\varphi$, since in the honest execution of the
protocol with a correct witness, $\overline{P}\varphi$ is the unique codeword
$P_0$ of $\dashL_2$ with $P_0[j]=0$ for $j\in [m]$. The complete protocol for
distributed quadratic check appears in Figure \ref{fig:distquadcheck}.


\begin{figure}[h!]
\centering
\begin{framed}
\begin{itemize}
\item $\distproxTwoD(\FF,\GG,\ell,L_1,L_2,\bm{c};[[\overline{U}]],[[\bm{\omega}]])$:
\item {\bf Relation}: $(\overline{U},\bm{\omega})=\open(\bm{c})$ and
$\overline{U}\mc{T}\in \mc{C}_2$.
\begin{enumerate}[{\rm 1.}]
\item $\distprover\rightarrow \Ag$: Samples random codeword $u^\xi_0\in L_2$ and
computes $d^\xi_0=\comm(u^\xi_0,\nu^\xi_0)$ for randomly sampled $\nu^\xi_0$.
Sends $d^\xi_0$ to $\Ag$.
\item {\color{red} $\Ag\rightarrow \verifier$: $\Ag$ computes $d_0=\sum_{\xi\in
K}d^\xi_0$ and sends $d_0$ to $\verifier$ }.
\item $\verifier\rightarrow \distprover$: Verifier samples $\tau\sample \FF^m$,
$\delta\sample \FF^{h-m}$ and sends them to $\distprover$.
\item $\Ag\leftrightarrow \verifier$ compute: $\mu=\mc{T}\tau$,
$\mathsf{cm}=d_0+\sum_{i\in [\ell]}\mu_ic_i$, $x=\mc{H}_2\delta$.
\item $\distprover$ computes: $[[z]]^\xi=u^\xi_0+[[\overline{U}]]^\xi\mu$,
$[[\nu]]_\xi=\nu^\xi_0+\sum_{i\in [\ell]}\mu_i[[\omega_i]]^\xi$.
\item {\color{red} $\Ag$ computes: $z=\combine([[z]]^\xi)$,
$\nu=\combine([[\nu]]^\xi)$}.
\item $\Ag$ and $\verifier$ run the subprotocol:
	\begin{itemize}
	\item $b=\innerproduct(\FF,\GG,\bm{g},x,\mathsf{cm},0;z,\nu)$.
	\end{itemize}
\item $\verifier$ accepts if the subprotocol accepts.
\end{enumerate}
\end{itemize}
\end{framed}
\caption{Distributed Membership Test}
\label{fig:distprox2d}
\end{figure}


\begin{figure}[h!]
\centering
\begin{framed}
\begin{itemize}
\item {$\distproxThreeD(\FF,\GG,L_1,L_2,[\pi];[[\ewit]])$}:
\item {\bf Relation}: $\ewit=\open(\pi)$, $\ewit\in \mc{W}$.
\item {\bf Oracle Setup}: 
	\begin{itemize}
	\item $\distprover\rightarrow \Ag$: Each prover computes shares $[[\comoracle]]^\xi$ from $[[\ewit]]^\xi$ as $[[\comoracle]]^\xi=\comm([[\ewit]]^\xi)$ as in Section \ref{sec:construct_oracle}. 
	\item {\color{red} $\Ag$ computes: $\comoracle :=
\combine([[\comoracle]]^\xi)$ and sets $\pi := \comoracle$ as the oracle}.
	\end{itemize}
\begin{enumerate}[{\rm 1.}]
\item $\verifier\rightarrow\distprover$: Verifier samples $r\sample \FF^p$ and
sends $r$ to $\distprover$.
\item $\distprover$ computes:
	\begin{itemize}
	\item $\shr{\tilde{U}} := \sum_{i\in [p]}r_i\shr{\ewit}[i,\cdot,\cdot]$.
	\item $\shr{\tilde{c}_k} := \sum_{i\in [p]}\shr{\comoracle}[i,k]$ for
$k\in [\ell]$.
	\item $\shr{\tilde{\omega}_k} := \sum_{i\in [p]}O^\xi[i,k]$ for
$k\in [\ell]$.
	\end{itemize}
\item $\distprover\rightarrow\Ag$: The provers send $\shr{\tilde{\bm{c}}} :=
(\shr{\tilde{c}_1},\ldots,\shr{\tilde{c}_\ell})$ to $\Ag$.
\item {\color{red} $\Ag\rightarrow\verifier$: $\Ag$ computes $\tilde{\bm{c}} :=
\combine(\shr{\tilde{\bm{c}}})$ and sends
$\tilde{\bm{c}}=(\tilde{c}_1,\ldots,\tilde{c}_\ell)$ to $\verifier$}.
\item $\Ag$ and $\verifier$ run the subprotocol:
	\begin{itemize}
	\item
$b=\distproxTwoD(\FF,\GG,\ell,L_1,L_2,\tilde{\bm{c}};\shr{\tilde{U}})$.
	\end{itemize}
\item $\verifier$ queries: $\verifier$ samples $Q\subseteq [n]$ of size $t$ and
makes oracle queries for positions in $Q$.
\item Oracle Answers: The oracle responds with columns $\pi[\cdot,k]$ for $k\in
Q$.
\item $\verifier$ checks: The verifier checks $\sum_{i\in
[p]}r_i\pi[i,k]=\sum_{i\in [\ell]}\mc{T}[i,k]\tilde{c}_i$ for $k\in Q$.
\item $\verifier$ accepts if the above check succeeds and $b=1$. 
\end{enumerate}
\end{itemize}
\end{framed}
\caption{Distributed 3D Proximity Protocol}
\label{fig:distprox3d}
\end{figure}

Our next lemma captures the fact that the aggregator $\Ag$ gains no additional
knowledge from the messages sent by the provers in the distributed protocol
$\distlinearcheck$. 

\begin{lemma}\label{lem:distlincheckzk}
For $\xi\in [K]$, let $\View^\xi_\Ag$ denote the view of the aggregator $\Ag$ in the distributed
linear check protocol consisting of messages from the prover $\distprover$ with
witness $\shr{\wit}$. Then there exists an efficient simulator $\simulator$
which outputs a view indistinguishalbe from the joint view $\langle
\View^1_\Ag,\ldots,\View^K_\Ag\rangle$ 
%whenever $A\wit=b$ for
%$\wit=\combine(\shr{\wit})$.
\end{lemma}
\begin{proof}

Let $r,\{j_u,k_u\}_{u\in
[t]},\beta,\tau,\delta,\rho,\tilde{\tau},\tilde{\delta}$ denote the verifier
randomness, which is shared by each view. Consider other messages in
$\View^\xi_\Ag$. Let 
$c_0^\xi,c_1^\xi,\ldots,c_{s+\ell}^\xi,d_0^\xi,\tilde{c}_1^\xi,\ldots,\tilde{c}_\ell^\xi,\tilde{d}_0^\xi,\{\pi^\xi[\cdot,k_u]\}_{u\in
[t]}$ denote the commitments sent by $\distprover$. Similarly let 
$\nu^\xi,\omega^\xi,\{\chi^\xi_u\}_{u\in [t]},\{O^\xi[\cdot,k_u]\}_{u\in [t]})$
denote the commitment randomness sent by the $\distprover$. Finally, the
(extended) view also includes $\ewit^\xi[\cdot,\cdot,k_u]$ for $u\in [t]$,
$z^\xi=u_0^\xi+P^\xi\mu$,
$\tilde{z}^\xi=\tilde{u}^\xi_0+\tilde{U}^\xi\tilde{\mu}$ and ${z'}^\xi=\beta
P^\xi_0 + \overline{P}^\xi\varphi + \shr{0^h}$. Note that these variables were
included in our definition of the extended view of the single prover case. As in the simulation of the
single prover case, given the verifier randomness, all variables except
${z'}^\xi$ are distributed independent of the witness used by the prover
$\distprover$, and can thus be simulated as in the zero knowledge simulation.
The joint distribution of ${z'}^1,\ldots,{z'}^K$ can be seen to be:
({\color{red} Protik to finish the argument}).
\begin{itemize}
\item Uniform distribution on $\FF^h$ if one of the provers sends an incorrect
share of $0^h$.
\item Uniform distribution on the set codewords $P_0$ in $\dashL_2$ satisfying
$\sum_{j\in [m]}P_0[j]=0$ if all the provers follow the protocol and
jointly have the correct witness.
\item Provers follow the protocol but with incorrect inputs: in lemma ~\ref{lem:privacy}, we described a simulator which can simulate the messages of the honest parties. 
\end{itemize}

Thus, in each case, the view of the aggregator $\Ag$ can be perfectly simulated.
\end{proof}
\begin{lemma}\label{lem:privacy}
	For $\xi\in [K]$, let $\View^{\xi}_{\adv}$\pnote{fix notation} denotes the view of the adversary $\adv$ corrupting parties in $I$, where $I$ is a proper subset of the sets of the provers. Then there is a $\ppt$ simulator $\Sim$ which can generate a view of $\adv$ which is indistinguishable from the real execution of the protocol given there is a secure MPC for multiplication which withstand against the corrupt parties in $I$. \pnote{(Maybe a broadcast required)}
\end{lemma}

\begin{proof}
	To prove the above theorem we will design a simulator $\Sim$ which has access to the ideal functionality $\Func_{\DPZK}$ (~\ref{func:DPZK}). Provers in $I$ encode and commit to their inputs and $\Sim$ gets $\shr{\comoracle}, \shr{\comoracle}_a$ $\forall a\in\{x,y,z\}$ and $\forall \xi \in I$. Since the commitment is extractable, so $\Sim$ extracts and gets shares of $\wit, x,y,z$ of the parties in $I$. 
	%Now $\Sim$ checks if all the steps of Linear and Quadratic checks are done using the same inputs extracted by $\Sim$. If yes, then $\Sim$ calls the functionality $\Func_{\DPZK}$ if it outputs 1, then $\Sim$ uses the same approach of  
	%$\Sim$ picks random challenges for both linear and quadratic checks on behalf of the verifier (picking random challenges on behalf of the verifier is fine since the verifier is semi-honest). 
	Then $\Sim$ uses the simulator for \name and gets an accepting transcript. Using that computes $\shr{\comoracle}, \shr{\comoracle}_a$ $\forall \xi\notin I$, using homomorphic property of the commitment scheme.
	$\Sim$ gets $\shr{c_0}, \shr{c_1}, \ldots, \shr{c_{s+\ell}}$ and $\shr{Z}$ for all $\xi\in I$ in the linear check, as all the provers are sending this values to $\Ag$, which is done using broadcast. Using extraction of commitment $\Sim$ gets the decommitted values. If there is some inconsistency in the values extracted from $\shr{\comoracle}, \shr{\comoracle}_a$ $\forall a\in\{x,y,z\}$ and $\forall \xi \in I$ and these decommitted values then
	%output $\abort$, else continue.
	sets $\mathsf{state}$ as fail, otherwise pass.
	For quadratic check, $\Sim$ calls the simulator, $\Sim_M$, of the secure multiplication protocol and extracts the input of the MPC, and does the consistency check, as in the linear case. If there is some inconsistency then 
	%output $\abort$, else continue.
	sets $\mathsf{state}$ as fail, otherwise, pass.
	Similarly, $\mathsf{state}$ is set for the remaining part of the protocol.
	(This part is informally stated here, details will be provided in the full version.)
	Now for both the protocols if $\mathsf{state}$ remains pass till the provers send the final messages to $\Ag$, which are the witnesses of the inner product arguments, 
	\pnote{Should we add the details such as what are the consistency checks? From the protocol that is quite evident.}
	then $\Sim$ calls the functionality $\Func_{\DPZK}$ with the input $\wit, x,y,z$ of the parties in $I$. If it outputs 1, then $\Sim$ generates the final messages of the honest parties using the accepting transcript produced by the zero-knowledge simulator, else $\Sim$ picks any random message which is consistent with the transcript so far.
	
	If there is some inconsistency in some intermediate step, i.e., the $\mathsf{state}$ is fail, then $\Sim$ calls the functionality $\Func_{\DPZK}$ on some random value and proceeds accordingly with the simulation.
	
	This proves that the view of the corrupt provers can be simulated, which ensures privacy of the honest provers.
\end{proof}

%\end{enumerate}
   



\subsection{Non-interactive}
IOP to NIROP
